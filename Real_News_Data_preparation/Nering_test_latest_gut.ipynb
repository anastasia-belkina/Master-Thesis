{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb0608d-ea37-4511-9e6c-c23878e58d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a6b9f4-f37c-414a-b9d4-065d70b7e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "column_names = [\"Sentence\", \"Label\"]\n",
    "df_test_sen_lab = pd.read_csv('datasets_cleaned/test_cleaned.txt', sep='\\t', header=None, names=column_names)\n",
    "\n",
    "# Load Spacy model\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aedead74-7383-491c-a89e-d9219bb3f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional terms for entity extraction\n",
    "additional_terms = {\"person\", \"man\", \"woman\", \"police\", \"administration\", \"immigrants\",\n",
    "                   \"president\", \"minister\", \"senator\", \"representative\", \"governor\", \"mayor\", \"council\", \"secretary\", \"ambassador\",\n",
    "                   \"chancellor\", \"parliamentary\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04339fdc-0c96-44c0-bc5c-80fcec9214a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = {\"i\", \"me\", \"myself\", \"you\", \"yourself\", \"he\", \"she\", \"him\", \"her\", \"they\", \"them\", \"himself\", \"herself\", \"themself\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c84c9db-9905-4bb8-a0c7-70fc84e94128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interacting_entities(doc):\n",
    "    # Define the priority labels for entities to be extracted\n",
    "    priority_labels = [\"PERSON\", \"NORP\", \"ORG\", \"GPE\"]\n",
    "    valid_entities = []\n",
    "\n",
    "    for label in priority_labels:\n",
    "        # If we already have two different entities, stop searching\n",
    "        if len(valid_entities) >= 2:\n",
    "            if valid_entities[0][2].lower() != valid_entities[1][2].lower(): break # 2 entities cant be the same entities \n",
    "\n",
    "        # Extract entities matching the current priority label\n",
    "        current_entities = [(ent.start_char, ent.end_char, ent.text) for ent in doc.ents if ent.label_ == label]\n",
    "        valid_entities.extend(current_entities)\n",
    "\n",
    "        # Additional check for PERSON label: include tokens from additional terms if fewer than 2 entities found\n",
    "        if label == \"PERSON\" and len(valid_entities) < 2:\n",
    "            for token in doc:\n",
    "                if token.text.lower() in additional_terms:\n",
    "                    valid_entities.append((token.idx, token.idx + len(token.text), token.text))\n",
    "\n",
    "        # Additional check after the last label: include tokens from pronouns if fewer than 2 entities found\n",
    "        if label == \"GPE\" and len(valid_entities) < 2:\n",
    "            for token in doc:\n",
    "                if token.text.lower() in pronouns:\n",
    "                    valid_entities.append((token.idx, token.idx + len(token.text), token.text))\n",
    "\n",
    "        # Sort entities by their start position\n",
    "        valid_entities = sorted(valid_entities, key=lambda x: x[0])\n",
    "\n",
    "        # Merge adjacent entities\n",
    "        merged_entities = []\n",
    "        i = 0\n",
    "        while i < len(valid_entities):\n",
    "            current_ent = valid_entities[i]\n",
    "            j = i + 1\n",
    "            while j < len(valid_entities) and valid_entities[j][0] <= current_ent[1] + 1:\n",
    "                current_ent = (current_ent[0], valid_entities[j][1], current_ent[2] + \" \" + valid_entities[j][2])\n",
    "                j += 1\n",
    "            merged_entities.append(current_ent)\n",
    "            i = j\n",
    "        valid_entities = merged_entities\n",
    "\n",
    "    # Return the first two entities if available\n",
    "    if len(valid_entities) >= 2:\n",
    "        return valid_entities[:2]\n",
    "    else:\n",
    "        return valid_entities\n",
    "\n",
    "\n",
    "\n",
    "def wrap_selected_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = find_interacting_entities(doc)\n",
    "    \n",
    "    formatted_text = text\n",
    "    offset = 0\n",
    "    for ent in entities:\n",
    "        start, end, ent_text = ent\n",
    "        start += offset\n",
    "        end += offset\n",
    "        formatted_text = formatted_text[:start] + '[' + ent_text + ']' + formatted_text[end:]\n",
    "        offset += 2  # 2 characters for the added brackets\n",
    "\n",
    "    # Construct the final formatted text with entity details\n",
    "    entity_count = len(entities)\n",
    "    if entity_count == 0:\n",
    "        formatted_text = formatted_text + \"\\t\" + \"0\" + \"\\t\" + \"None\" + \"\\t\" + \"None\"\n",
    "    elif entity_count == 1:\n",
    "        formatted_text = formatted_text + \"\\t\" + \"1\" + \"\\t\" + entities[0][2] + \"\\t\" + \"None\"\n",
    "    else:\n",
    "        formatted_text = formatted_text + \"\\t\" + \"2\" + \"\\t\" + entities[0][2] + \"\\t\" + entities[1][2]\n",
    "    \n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afabce16-5cbc-4ef2-9b5b-8f8a56099260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the function to the 'Sentence' column with sentence numbering\n",
    "df_test_sen_lab['Formatted_Sentence'] = df_test_sen_lab.apply(lambda row: wrap_selected_entities(row['Sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fe5a55-4070-4cae-868e-1227b409c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anastasiia Belkina\\AppData\\Local\\Temp\\ipykernel_16872\\2972666276.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_Form_sen_lab_sen_lab[\"Formatted_Sentence\"] = split_columns[0]\n"
     ]
    }
   ],
   "source": [
    "# Select the relevant columns\n",
    "df_test_Form_sen_lab_sen_lab = df_test_sen_lab[['Formatted_Sentence', 'Label']]\n",
    "\n",
    "# Split the 'Formatted_Sentence' column into multiple columns\n",
    "split_columns = df_test_Form_sen_lab_sen_lab['Formatted_Sentence'].str.split(\"\\t\", expand=True)\n",
    "\n",
    "# Assign the new columns to the DataFrame and rename them\n",
    "df_test_Form_sen_lab_sen_lab[\"Formatted_Sentence\"] = split_columns[0]\n",
    "df_test_Form_sen_lab_sen_lab[\"Num_of_ent\"] = split_columns[1].astype(int)\n",
    "df_test_Form_sen_lab_sen_lab[\"Ent_1\"] = split_columns[2]\n",
    "df_test_Form_sen_lab_sen_lab[\"Ent_2\"] = split_columns[3]\n",
    "\n",
    "# Select and reorder the final columns\n",
    "df_test_Form_sen_lab_sen_lab = df_test_Form_sen_lab_sen_lab[[\"Formatted_Sentence\", \"Ent_1\", \"Ent_2\", \"Num_of_ent\", \"Label\"]]\n",
    "\n",
    "# Save the new dataframe\n",
    "file_path = 'datasets_new_nered/test_new_ner.txt'\n",
    "df_test_Form_sen_lab_sen_lab.to_csv(file_path, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5b5d80-b605-44da-b47b-01ede9a3dcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formatted_Sentence</th>\n",
       "      <th>Ent_1</th>\n",
       "      <th>Ent_2</th>\n",
       "      <th>Num_of_ent</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>” Breitbart News has now reached out to the [T...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Ivanka</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Phoebe Nora Mary Prince], 15, committed suici...</td>\n",
       "      <td>Phoebe Nora Mary Prince</td>\n",
       "      <td>Phoebe Prince</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notably, the department says about 30 emails t...</td>\n",
       "      <td>U. S.</td>\n",
       "      <td>Benghazi</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Meacham] was recently featured by the San Die...</td>\n",
       "      <td>Meacham</td>\n",
       "      <td>Trump</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But Portland's city code prohibits persons fro...</td>\n",
       "      <td>Root</td>\n",
       "      <td>Ashton</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>The Trump [administration] is likely to start ...</td>\n",
       "      <td>administration</td>\n",
       "      <td>Obama</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Well, we do have challenges, but were not stup...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>president</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>He was also fired from a season of \"The Celebr...</td>\n",
       "      <td>\"Hulk Hogan</td>\n",
       "      <td>Hogan</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>[The Hong Kong Monetary Authority] started sel...</td>\n",
       "      <td>The Hong Kong Monetary Authority</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>Mr. [Band] and an associate introduced top cor...</td>\n",
       "      <td>Band</td>\n",
       "      <td>president</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1623 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Formatted_Sentence  \\\n",
       "0     ” Breitbart News has now reached out to the [T...   \n",
       "1     [Phoebe Nora Mary Prince], 15, committed suici...   \n",
       "2     Notably, the department says about 30 emails t...   \n",
       "3     [Meacham] was recently featured by the San Die...   \n",
       "4     But Portland's city code prohibits persons fro...   \n",
       "...                                                 ...   \n",
       "1618  The Trump [administration] is likely to start ...   \n",
       "1619  Well, we do have challenges, but were not stup...   \n",
       "1620  He was also fired from a season of \"The Celebr...   \n",
       "1621  [The Hong Kong Monetary Authority] started sel...   \n",
       "1622  Mr. [Band] and an associate introduced top cor...   \n",
       "\n",
       "                                 Ent_1          Ent_2  Num_of_ent  Label  \n",
       "0                                Trump         Ivanka           2      0  \n",
       "1              Phoebe Nora Mary Prince  Phoebe Prince           2      0  \n",
       "2                                U. S.       Benghazi           2      0  \n",
       "3                              Meacham          Trump           2      0  \n",
       "4                                 Root         Ashton           2      0  \n",
       "...                                ...            ...         ...    ...  \n",
       "1618                    administration          Obama           2      3  \n",
       "1619                             Trump      president           2      3  \n",
       "1620                       \"Hulk Hogan          Hogan           2      1  \n",
       "1621  The Hong Kong Monetary Authority           U.S.           2      1  \n",
       "1622                              Band      president           2      1  \n",
       "\n",
       "[1623 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_Form_sen_lab_sen_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d47121-4e87-4ee5-9648-698b4f2af2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only those rows, where Num_of_ent = 2\n",
    "ent = [2]\n",
    "mask = df_test_Form_sen_lab_sen_lab['Num_of_ent'].isin(ent)\n",
    "df_test_Form_sen_lab_sen_lab_2 = df_test_Form_sen_lab_sen_lab[mask]\n",
    "df_test_Form_sen_lab_sen_lab_2 = df_test_Form_sen_lab_sen_lab_2.drop(columns=['Num_of_ent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0136e4e-5151-4228-9786-95b309aaef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'datasets_new_nered_2_ents/test.txt'\n",
    "df_test_Form_sen_lab_sen_lab_2.to_csv(file_path, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48191b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
