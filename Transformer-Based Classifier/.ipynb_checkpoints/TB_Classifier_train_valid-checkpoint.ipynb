{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6521c4d0-6d0d-4c55-aab7-35ecc459b3f8",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d252f4e7-e7ed-4e7b-b3f1-809334313152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anastasiia Belkina\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, logging, random, time\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from researchers_code.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67587f32-7f46-48e5-8bab-5296f13dc519",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133a1bf8-f213-415e-ab5a-715b4980190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Sentence\", \"Ent_1\", \"Ent_2\", \"Label\"]\n",
    "\n",
    "# Define file paths\n",
    "test_file = 'datasets/test_with_scobes.txt'\n",
    "valid_file = 'datasets/valid_with_scobes.txt'\n",
    "train_file = 'datasets/train_with_scobes.txt'\n",
    "\n",
    "# Load the datasets\n",
    "test_data = pd.read_csv(test_file, sep='\\t', names=column_names)\n",
    "valid_data = pd.read_csv(valid_file, sep='\\t', names=column_names)\n",
    "train_data = pd.read_csv(train_file, sep='\\t', names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d111f8b6-4d05-438d-9756-f7b6dcfdb1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Ent_1</th>\n",
       "      <th>Ent_2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Bush II] — released a statement opposing [Don...</td>\n",
       "      <td>Bush II</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after the [Dallas] murders — by blaming “syste...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>White Americans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Zappos] CEO [Tony Hsieh] has been praised for...</td>\n",
       "      <td>Zappos</td>\n",
       "      <td>Tony Hsieh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But [Shaffer] and other experts faulted [Clint...</td>\n",
       "      <td>Shaffer</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kulitta, music composition software written by...</td>\n",
       "      <td>Donya Quick</td>\n",
       "      <td>Johann Sebastian Bach</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Ent_1  \\\n",
       "0  [Bush II] — released a statement opposing [Don...      Bush II   \n",
       "1  after the [Dallas] murders — by blaming “syste...       Dallas   \n",
       "2  [Zappos] CEO [Tony Hsieh] has been praised for...       Zappos   \n",
       "3  But [Shaffer] and other experts faulted [Clint...      Shaffer   \n",
       "4  Kulitta, music composition software written by...  Donya Quick   \n",
       "\n",
       "                   Ent_2  Label  \n",
       "0           Donald Trump      3  \n",
       "1        White Americans      3  \n",
       "2             Tony Hsieh      1  \n",
       "3                Clinton      3  \n",
       "4  Johann Sebastian Bach      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26378c-cd6d-4ddb-a7e2-4c9951c4ff0f",
   "metadata": {},
   "source": [
    "There are five **labels:**\n",
    "- 0 - neutral\n",
    "- 1 - positive (p → q)\n",
    "- 2 - positive (q → p)\n",
    "- 3 - negative (p → q)\n",
    "- 4 - negative (q → p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24eefb3-d322-423d-8902-39294ed79645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496144a-c346-405b-9a94-5622cafde6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da89f455-b322-4bbe-937c-5f003adc0bc0",
   "metadata": {},
   "source": [
    "# Applying the Model DSE2QA of the Researchers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4355fc-d668-4c51-abba-43e67e2b65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anastasiia Belkina\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Anastasiia Belkina\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anastasiia Belkina\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m logger\u001b[38;5;241m.\u001b[39maddHandler(f_handler)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Call the main function with the args object\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m main(args, train_path, logger, exp_id)\n",
      "File \u001b[1;32m~\\MANNHEIM\\MASTER_THESIS_CODE\\Transformer-Based Classifier\\researchers_code\\dse2qa.py:212\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args, train_path, logger, exp_id)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m#input_id, attention_mask, y = input_id.cuda(), attention_mask.cuda(), y.cuda()\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Change for inputs and tensors\u001b[39;00m\n\u001b[0;32m    210\u001b[0m input_id, attention_mask, y \u001b[38;5;241m=\u001b[39m input_id\u001b[38;5;241m.\u001b[39mto(device), attention_mask\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 212\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(input_id, attention_mask)\n\u001b[0;32m    213\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m loss_ce(pred, y)\n\u001b[0;32m    214\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(loss_all)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\MANNHEIM\\MASTER_THESIS_CODE\\Transformer-Based Classifier\\researchers_code\\dse2qa.py:25\u001b[0m, in \u001b[0;36mTransformerClassifierWithAuxiliarySentence.forward\u001b[1;34m(self, input, attention_mask)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, attention_mask):\n\u001b[0;32m     24\u001b[0m     _, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(out)\n\u001b[0;32m     26\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Transfor_Based_Classifier\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "from researchers_code.dse2qa import main  # Correct import for main function\n",
    "\n",
    "# Simulate argparse by creating an Args class\n",
    "class Args:\n",
    "    def __init__(self, input_type, resample, max_epoch, batch_size, random_seed, pretrain_type, temperature):\n",
    "        self.input_type = input_type # Set input_type to (\"T(emplate)\" or \"P(seudo)\")\n",
    "        self.resample = resample # Set resample to (\"none\", \"up\", \"down\")\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.random_seed = random_seed\n",
    "        self.pretrain_type = pretrain_type  # Set pretrain_type to \"roberta\" or \"spanbert\"\n",
    "        self.temperature = temperature # needed otherwise doesnt work\n",
    "\n",
    "# Manually create an args object\n",
    "args = Args(input_type=\"T\", resample=\"none\", max_epoch=3, batch_size=40, random_seed=20180422, pretrain_type=\"roberta\", temperature = 1.0)  \n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(args.random_seed)\n",
    "random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "torch.cuda.manual_seed_all(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(args.random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define the appropriate train_path based on the resample strategy\n",
    "if args.resample == \"none\":\n",
    "    train_path = \"dataset/train.txt\"\n",
    "elif args.resample == \"up\":\n",
    "    train_path = \"dataset/train_over.txt\"\n",
    "elif args.resample == \"down\":\n",
    "    train_path = \"dataset/train_under.txt\"\n",
    "else:\n",
    "    raise TypeError(\"Invalid resample option\")\n",
    "\n",
    "# Create a unique experiment ID based on parameters\n",
    "exp_id = f\"DSE2QA_{args.input_type}_{args.resample}_{args.max_epoch}_{args.batch_size}_{args.random_seed}\"\n",
    "\n",
    "# Ensure the 'out' directory exists\n",
    "os.makedirs(\"out\", exist_ok=True)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(exp_id)\n",
    "f_handler = logging.FileHandler(f\"out/{exp_id}.txt\", mode=\"w\")\n",
    "f_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(f_handler)\n",
    "\n",
    "# Call the main function with the args object\n",
    "main(args, train_path, logger, exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b8993-b130-488e-b537-a10c9e7ffa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410500da-aab5-4abe-99b8-0a7400d0e462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ed586-566b-4e56-955b-9b1eb774a00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4797d7-0882-42c3-90b6-432dd798b7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303db45-3cad-4200-beb2-9270dfd9cbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
