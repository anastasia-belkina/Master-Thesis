{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee484548-0f4d-4182-a70f-aef0f0cd5b96",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d02f264-f222-4ffb-be3b-f0097f988b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import stanza\n",
    "import ast\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import verbnet as vn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b106f5-091e-4100-af31-f7677c66f1de",
   "metadata": {},
   "source": [
    "# Preprocessed Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1049d0-bd96-4662-988d-0db76fe1a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "column_names = [\"Sentence\", \"Label\", \"tokens_pos\", \"entities\", \"dependencies\"]\n",
    "#df_train_ready = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/df_train_shuffled.txt', sep='\\t', names=column_names)\n",
    "#df_valid_ready = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/df_valid_shuffled.txt', sep='\\t', names=column_names)\n",
    "#df_test_ready = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/df_test_shuffled.txt', sep='\\t', names=column_names)\n",
    "\n",
    "shuffled_df = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/shuffled_df.txt', sep='\\t', names=column_names)\n",
    "\n",
    "# Unite whole data in one dataframe\n",
    "#merged_df = pd.concat([df_train_ready, df_valid_ready, df_test_ready], ignore_index=True)\n",
    "\n",
    "# Shuffle the merged dataframe\n",
    "#shuffled_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the DataFrame to a text file without column headings\n",
    "#shuffled_df.to_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/shuffled_df.txt', header=False, index=False, sep='\\t')\n",
    "\n",
    "# Remove leading and trailing spaces in the \"Sentence\" column\n",
    "shuffled_df['Sentence'] = shuffled_df['Sentence'].str.strip()\n",
    "\n",
    "# First 100 rows for examples\n",
    "#shuffled_df = shuffled_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32502fac-70ca-4c2c-83be-a0f206d6b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The faculty's Academic Senate threw its suppor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('The', 'DET'), ('faculty', 'NOUN'), (\"'s\", '...</td>\n",
       "      <td>[('Academic Senate', 'ORG'), ('Monday', 'DATE'...</td>\n",
       "      <td>[('The', 2, 'det'), ('faculty', 5, 'nmod:poss'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But the true scale of the movement remains unc...</td>\n",
       "      <td>3</td>\n",
       "      <td>[('But', 'CCONJ'), ('the', 'DET'), ('true', 'A...</td>\n",
       "      <td>[('Miskito', 'NORP'), ('Nicaraguan', 'NORP')]</td>\n",
       "      <td>[('But', 8, 'cc'), ('the', 4, 'det'), ('true',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Branstad is ripping Cruz for taking the bold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('(', 'PUNCT'), ('Branstad', 'PROPN'), ('is',...</td>\n",
       "      <td>[('Branstad', 'PERSON'), ('Cruz', 'PERSON'), (...</td>\n",
       "      <td>[('(', 4, 'punct'), ('Branstad', 4, 'nsubj'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But the Marlins have failed to make the postse...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('But', 'CCONJ'), ('the', 'DET'), ('Marlins',...</td>\n",
       "      <td>[('Marlins', 'ORG'), ('Loria', 'PERSON')]</td>\n",
       "      <td>[('But', 5, 'cc'), ('the', 3, 'det'), ('Marlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is nothing new yet on the table, but one...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('There', 'PRON'), ('is', 'VERB'), ('nothing'...</td>\n",
       "      <td>[('one', 'CARDINAL'), ('Gannett', 'ORG'), ('Tr...</td>\n",
       "      <td>[('There', 2, 'expl'), ('is', 0, 'root'), ('no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label  \\\n",
       "0  The faculty's Academic Senate threw its suppor...      0   \n",
       "1  But the true scale of the movement remains unc...      3   \n",
       "2  (Branstad is ripping Cruz for taking the bold ...      0   \n",
       "3  But the Marlins have failed to make the postse...      0   \n",
       "4  There is nothing new yet on the table, but one...      1   \n",
       "\n",
       "                                          tokens_pos  \\\n",
       "0  [('The', 'DET'), ('faculty', 'NOUN'), (\"'s\", '...   \n",
       "1  [('But', 'CCONJ'), ('the', 'DET'), ('true', 'A...   \n",
       "2  [('(', 'PUNCT'), ('Branstad', 'PROPN'), ('is',...   \n",
       "3  [('But', 'CCONJ'), ('the', 'DET'), ('Marlins',...   \n",
       "4  [('There', 'PRON'), ('is', 'VERB'), ('nothing'...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [('Academic Senate', 'ORG'), ('Monday', 'DATE'...   \n",
       "1      [('Miskito', 'NORP'), ('Nicaraguan', 'NORP')]   \n",
       "2  [('Branstad', 'PERSON'), ('Cruz', 'PERSON'), (...   \n",
       "3          [('Marlins', 'ORG'), ('Loria', 'PERSON')]   \n",
       "4  [('one', 'CARDINAL'), ('Gannett', 'ORG'), ('Tr...   \n",
       "\n",
       "                                        dependencies  \n",
       "0  [('The', 2, 'det'), ('faculty', 5, 'nmod:poss'...  \n",
       "1  [('But', 8, 'cc'), ('the', 4, 'det'), ('true',...  \n",
       "2  [('(', 4, 'punct'), ('Branstad', 4, 'nsubj'), ...  \n",
       "3  [('But', 5, 'cc'), ('the', 3, 'det'), ('Marlin...  \n",
       "4  [('There', 2, 'expl'), ('is', 0, 'root'), ('no...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab333b5-5052-4dc7-aa98-b229e3cd04e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6c6add-31b2-4365-82c7-983097d03a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    3390\n",
       "3    1631\n",
       "1     814\n",
       "4     237\n",
       "2     155\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade7978-08a0-4c84-be4c-be6ed20f1d04",
   "metadata": {},
   "source": [
    "# Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aaba528-c606-4797-aeee-52437715a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary: 0 - neutral, 1 - positive, 2 - negative\n",
    "label_mapping = {2: 1, 3: 2, 4: 2}\n",
    "shuffled_df['Label'] = shuffled_df['Label'].replace(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ce2526-47fa-4485-8d66-1e9810305f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The faculty's Academic Senate threw its suppor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('The', 'DET'), ('faculty', 'NOUN'), (\"'s\", '...</td>\n",
       "      <td>[('Academic Senate', 'ORG'), ('Monday', 'DATE'...</td>\n",
       "      <td>[('The', 2, 'det'), ('faculty', 5, 'nmod:poss'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But the true scale of the movement remains unc...</td>\n",
       "      <td>2</td>\n",
       "      <td>[('But', 'CCONJ'), ('the', 'DET'), ('true', 'A...</td>\n",
       "      <td>[('Miskito', 'NORP'), ('Nicaraguan', 'NORP')]</td>\n",
       "      <td>[('But', 8, 'cc'), ('the', 4, 'det'), ('true',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Branstad is ripping Cruz for taking the bold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('(', 'PUNCT'), ('Branstad', 'PROPN'), ('is',...</td>\n",
       "      <td>[('Branstad', 'PERSON'), ('Cruz', 'PERSON'), (...</td>\n",
       "      <td>[('(', 4, 'punct'), ('Branstad', 4, 'nsubj'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But the Marlins have failed to make the postse...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('But', 'CCONJ'), ('the', 'DET'), ('Marlins',...</td>\n",
       "      <td>[('Marlins', 'ORG'), ('Loria', 'PERSON')]</td>\n",
       "      <td>[('But', 5, 'cc'), ('the', 3, 'det'), ('Marlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is nothing new yet on the table, but one...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('There', 'PRON'), ('is', 'VERB'), ('nothing'...</td>\n",
       "      <td>[('one', 'CARDINAL'), ('Gannett', 'ORG'), ('Tr...</td>\n",
       "      <td>[('There', 2, 'expl'), ('is', 0, 'root'), ('no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label  \\\n",
       "0  The faculty's Academic Senate threw its suppor...      0   \n",
       "1  But the true scale of the movement remains unc...      2   \n",
       "2  (Branstad is ripping Cruz for taking the bold ...      0   \n",
       "3  But the Marlins have failed to make the postse...      0   \n",
       "4  There is nothing new yet on the table, but one...      1   \n",
       "\n",
       "                                          tokens_pos  \\\n",
       "0  [('The', 'DET'), ('faculty', 'NOUN'), (\"'s\", '...   \n",
       "1  [('But', 'CCONJ'), ('the', 'DET'), ('true', 'A...   \n",
       "2  [('(', 'PUNCT'), ('Branstad', 'PROPN'), ('is',...   \n",
       "3  [('But', 'CCONJ'), ('the', 'DET'), ('Marlins',...   \n",
       "4  [('There', 'PRON'), ('is', 'VERB'), ('nothing'...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [('Academic Senate', 'ORG'), ('Monday', 'DATE'...   \n",
       "1      [('Miskito', 'NORP'), ('Nicaraguan', 'NORP')]   \n",
       "2  [('Branstad', 'PERSON'), ('Cruz', 'PERSON'), (...   \n",
       "3          [('Marlins', 'ORG'), ('Loria', 'PERSON')]   \n",
       "4  [('one', 'CARDINAL'), ('Gannett', 'ORG'), ('Tr...   \n",
       "\n",
       "                                        dependencies  \n",
       "0  [('The', 2, 'det'), ('faculty', 5, 'nmod:poss'...  \n",
       "1  [('But', 8, 'cc'), ('the', 4, 'det'), ('true',...  \n",
       "2  [('(', 4, 'punct'), ('Branstad', 4, 'nsubj'), ...  \n",
       "3  [('But', 5, 'cc'), ('the', 3, 'det'), ('Marlin...  \n",
       "4  [('There', 2, 'expl'), ('is', 0, 'root'), ('no...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af8d5ed-9357-4ded-970e-eed179b2ebef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e5a722-13c5-4d28-9e66-6713f70950f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    3390\n",
       "2    1868\n",
       "1     969\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86202b1-ab31-408a-b9e6-8a7433be6a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The faculty's Academic Senate threw its suppor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('The', 'DET'), ('faculty', 'NOUN'), (\"'s\", '...</td>\n",
       "      <td>[('Academic Senate', 'ORG'), ('Monday', 'DATE'...</td>\n",
       "      <td>[('The', 2, 'det'), ('faculty', 5, 'nmod:poss'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But the true scale of the movement remains unc...</td>\n",
       "      <td>2</td>\n",
       "      <td>[('But', 'CCONJ'), ('the', 'DET'), ('true', 'A...</td>\n",
       "      <td>[('Miskito', 'NORP'), ('Nicaraguan', 'NORP')]</td>\n",
       "      <td>[('But', 8, 'cc'), ('the', 4, 'det'), ('true',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Branstad is ripping Cruz for taking the bold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('(', 'PUNCT'), ('Branstad', 'PROPN'), ('is',...</td>\n",
       "      <td>[('Branstad', 'PERSON'), ('Cruz', 'PERSON'), (...</td>\n",
       "      <td>[('(', 4, 'punct'), ('Branstad', 4, 'nsubj'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But the Marlins have failed to make the postse...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('But', 'CCONJ'), ('the', 'DET'), ('Marlins',...</td>\n",
       "      <td>[('Marlins', 'ORG'), ('Loria', 'PERSON')]</td>\n",
       "      <td>[('But', 5, 'cc'), ('the', 3, 'det'), ('Marlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is nothing new yet on the table, but one...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('There', 'PRON'), ('is', 'VERB'), ('nothing'...</td>\n",
       "      <td>[('one', 'CARDINAL'), ('Gannett', 'ORG'), ('Tr...</td>\n",
       "      <td>[('There', 2, 'expl'), ('is', 0, 'root'), ('no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>Conservatives have sided with government moves...</td>\n",
       "      <td>2</td>\n",
       "      <td>[('Conservatives', 'PROPN'), ('have', 'AUX'), ...</td>\n",
       "      <td>[('Conservatives', 'NORP'), ('Shin', 'PERSON')...</td>\n",
       "      <td>[('Conservatives', 3, 'nsubj'), ('have', 3, 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>However, former prosecutor Andrew McCarthy, no...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('However', 'ADV'), (',', 'PUNCT'), ('former'...</td>\n",
       "      <td>[('Andrew McCarthy', 'PERSON'), ('National Rev...</td>\n",
       "      <td>[('However', 15, 'advmod'), (',', 1, 'punct'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>Dunham’s accusing the left of “hostility” and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('Dunham', 'PROPN'), ('’s', 'AUX'), ('accusin...</td>\n",
       "      <td>[('Dunham’s', 'PERSON'), ('thousands', 'CARDIN...</td>\n",
       "      <td>[('Dunham', 3, 'nsubj'), ('’s', 3, 'aux'), ('a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>In the aftermath of the attack, Thoiry is warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('In', 'ADP'), ('the', 'DET'), ('aftermath', ...</td>\n",
       "      <td>[('Thoiry', 'PERSON'), ('European', 'NORP')]</td>\n",
       "      <td>[('In', 3, 'case'), ('the', 3, 'det'), ('after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Guillermo Lasso, the losing conservative candi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[('Guillermo', 'PROPN'), ('Lasso', 'PROPN'), (...</td>\n",
       "      <td>[('Guillermo Lasso', 'PERSON'), ('24', 'CARDIN...</td>\n",
       "      <td>[('Guillermo', 9, 'nsubj'), ('Lasso', 1, 'flat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6227 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Label  \\\n",
       "0     The faculty's Academic Senate threw its suppor...      0   \n",
       "1     But the true scale of the movement remains unc...      2   \n",
       "2     (Branstad is ripping Cruz for taking the bold ...      0   \n",
       "3     But the Marlins have failed to make the postse...      0   \n",
       "4     There is nothing new yet on the table, but one...      1   \n",
       "...                                                 ...    ...   \n",
       "6222  Conservatives have sided with government moves...      2   \n",
       "6223  However, former prosecutor Andrew McCarthy, no...      0   \n",
       "6224  Dunham’s accusing the left of “hostility” and ...      0   \n",
       "6225  In the aftermath of the attack, Thoiry is warn...      0   \n",
       "6226  Guillermo Lasso, the losing conservative candi...      2   \n",
       "\n",
       "                                             tokens_pos  \\\n",
       "0     [('The', 'DET'), ('faculty', 'NOUN'), (\"'s\", '...   \n",
       "1     [('But', 'CCONJ'), ('the', 'DET'), ('true', 'A...   \n",
       "2     [('(', 'PUNCT'), ('Branstad', 'PROPN'), ('is',...   \n",
       "3     [('But', 'CCONJ'), ('the', 'DET'), ('Marlins',...   \n",
       "4     [('There', 'PRON'), ('is', 'VERB'), ('nothing'...   \n",
       "...                                                 ...   \n",
       "6222  [('Conservatives', 'PROPN'), ('have', 'AUX'), ...   \n",
       "6223  [('However', 'ADV'), (',', 'PUNCT'), ('former'...   \n",
       "6224  [('Dunham', 'PROPN'), ('’s', 'AUX'), ('accusin...   \n",
       "6225  [('In', 'ADP'), ('the', 'DET'), ('aftermath', ...   \n",
       "6226  [('Guillermo', 'PROPN'), ('Lasso', 'PROPN'), (...   \n",
       "\n",
       "                                               entities  \\\n",
       "0     [('Academic Senate', 'ORG'), ('Monday', 'DATE'...   \n",
       "1         [('Miskito', 'NORP'), ('Nicaraguan', 'NORP')]   \n",
       "2     [('Branstad', 'PERSON'), ('Cruz', 'PERSON'), (...   \n",
       "3             [('Marlins', 'ORG'), ('Loria', 'PERSON')]   \n",
       "4     [('one', 'CARDINAL'), ('Gannett', 'ORG'), ('Tr...   \n",
       "...                                                 ...   \n",
       "6222  [('Conservatives', 'NORP'), ('Shin', 'PERSON')...   \n",
       "6223  [('Andrew McCarthy', 'PERSON'), ('National Rev...   \n",
       "6224  [('Dunham’s', 'PERSON'), ('thousands', 'CARDIN...   \n",
       "6225       [('Thoiry', 'PERSON'), ('European', 'NORP')]   \n",
       "6226  [('Guillermo Lasso', 'PERSON'), ('24', 'CARDIN...   \n",
       "\n",
       "                                           dependencies  \n",
       "0     [('The', 2, 'det'), ('faculty', 5, 'nmod:poss'...  \n",
       "1     [('But', 8, 'cc'), ('the', 4, 'det'), ('true',...  \n",
       "2     [('(', 4, 'punct'), ('Branstad', 4, 'nsubj'), ...  \n",
       "3     [('But', 5, 'cc'), ('the', 3, 'det'), ('Marlin...  \n",
       "4     [('There', 2, 'expl'), ('is', 0, 'root'), ('no...  \n",
       "...                                                 ...  \n",
       "6222  [('Conservatives', 3, 'nsubj'), ('have', 3, 'a...  \n",
       "6223  [('However', 15, 'advmod'), (',', 1, 'punct'),...  \n",
       "6224  [('Dunham', 3, 'nsubj'), ('’s', 3, 'aux'), ('a...  \n",
       "6225  [('In', 3, 'case'), ('the', 3, 'det'), ('after...  \n",
       "6226  [('Guillermo', 9, 'nsubj'), ('Lasso', 1, 'flat...  \n",
       "\n",
       "[6227 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a1cf9-5a57-493a-8c3a-7802f92ffba6",
   "metadata": {},
   "source": [
    "# Turning strings back to lists and tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77e79989-3230-4c6b-ba9c-17d47543c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(dependencies_str):\n",
    "    # Check if it's a string and if it appears to be in the list of tuples format\n",
    "    if isinstance(dependencies_str, str) and dependencies_str.startswith(\"[\") and dependencies_str.endswith(\"]\"):\n",
    "        try:\n",
    "            # Convert string representation of list back to actual list of tuples\n",
    "            return ast.literal_eval(dependencies_str)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error parsing: {dependencies_str}\")\n",
    "            raise e\n",
    "    elif isinstance(dependencies_str, list):\n",
    "        # If it's already a list, return as is\n",
    "        return dependencies_str\n",
    "    else:\n",
    "        # If it's another unexpected type, return as is or handle appropriately\n",
    "        return dependencies_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6e53857-0db5-4237-b8c7-e742c1fd955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to your datasets\n",
    "shuffled_df['dependencies'] = shuffled_df['dependencies'].apply(convert_to_list)\n",
    "shuffled_df['tokens_pos'] = shuffled_df['tokens_pos'].apply(convert_to_list)\n",
    "shuffled_df['entities'] = shuffled_df['entities'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5898c-ac22-4229-9a87-3a89b6c3912e",
   "metadata": {},
   "source": [
    "# Following the Modified Algorithm of Blame/Praise Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850365df-dec0-4b8f-a92e-6631d0347707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to check if a verb belongs to Foreseeability or Coercion groups\n",
    "\n",
    "def is_foreseeability_verb(verb):\n",
    "    # This function checks whether a verb belongs to a predefined set of foreseeability-related verb classes.\n",
    "    foreseeability_classes = {'communication', 'creation', 'consumption', 'competition', 'possession', 'motion'}\n",
    "    synsets = wn.synsets(verb, pos=wn.VERB)  # Fetches all verb synsets for the word\n",
    "    for synset in synsets:\n",
    "        lexname = synset.lexname().split('.')[1]  # Extracts the lexical category (i.e., type of action)\n",
    "        if lexname in foreseeability_classes:  # Checks if the lexical category is in the foreseeability class\n",
    "            return True  # Returns True if the verb matches any foreseeability category\n",
    "    return False  # If no match is found, returns False\n",
    "\n",
    "\n",
    "def is_coercion_verb(verb):\n",
    "    # This function checks whether a verb belongs to a predefined set of coercion-related VerbNet classes.\n",
    "    coercion_classes = {'urge-58.1', 'force-59', 'forbid-67'}\n",
    "    synsets = wn.synsets(verb, pos=wn.VERB)  # Fetches all verb synsets for the word\n",
    "    for synset in synsets:\n",
    "        lemma = synset.lemmas()[0]  # Gets the first lemma for each synset\n",
    "        vn_classes = lemma.key().split('%')[0]  # Extracts the lemma key\n",
    "        vn_class_ids = vn.classids(vn_classes)  # Fetches the VerbNet classes for the lemma\n",
    "        if any(vn_class in coercion_classes for vn_class in vn_class_ids):  # Checks for a match in coercion classes\n",
    "            return True  # If a match is found in coercion classes, return True\n",
    "    return False  # If no match is found, return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c70245b-fa64-4e29-ae20-84f7f8999ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_verb(word, tokens_pos):\n",
    "    \"\"\"\n",
    "    Check if the given word is a verb and passes the foreseeability and coercion checks.\n",
    "    \"\"\"\n",
    "    # Check if the word is a verb using tokens_pos\n",
    "    for token, pos in tokens_pos:\n",
    "        if token == word and 'VERB' in pos:  # Ensure the word is tagged as a verb\n",
    "            # Now check if it passes foreseeability and coercion checks\n",
    "            if is_foreseeability_verb(word) and not is_coercion_verb(word):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_conjunctions(verb_type_verbs, related_word, counter_j, index, dependencies, tokens_pos):\n",
    "    \"\"\"\n",
    "    Helper function to check and append conjunctions for specific verb types (xcomp, ccomp, parataxis, advcl).\n",
    "    It modifies the original verb list (e.g., xcomp_verbs, ccomp_verbs) by adding conjunctions directly.\n",
    "    \"\"\"\n",
    "    counter_x = 0\n",
    "    for conj in dependencies:\n",
    "        if len(conj) == 3:\n",
    "            conj_word, conj_head, conj_rel = conj\n",
    "            counter_x += 1\n",
    "            # Reset counter for punctuation after root - end of the sentence\n",
    "            if conj_rel == 'punct' and (conj_word == \".\" or conj_word == \":\"):\n",
    "                counter_x = 0\n",
    "            # Check if the conj word is a valid verb related to the current relation\n",
    "            if conj_head == counter_j and conj_rel == 'conj' and is_valid_verb(related_word, tokens_pos):\n",
    "                verb_type_verbs.append((conj_word, counter_x, index))  # Append conjunction to the respective verb list\n",
    "\n",
    "\n",
    "def handle_related_verbs(related_rel, related_word, counter_j, index, dependencies, tokens_pos, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs):\n",
    "    \"\"\"\n",
    "    Helper function to handle related verbs (xcomp, ccomp, parataxis, advcl).\n",
    "    Depending on the relation type, it adds the verb to the appropriate list and handles its conjunctions.\n",
    "    \"\"\"\n",
    "    if related_rel == 'xcomp':\n",
    "        xcomp_verbs.append((related_word, counter_j, index))  # xcomp relation to root\n",
    "        check_conjunctions(xcomp_verbs, related_word, counter_j, index, dependencies, tokens_pos)\n",
    "\n",
    "    elif related_rel == 'ccomp':\n",
    "        ccomp_verbs.append((related_word, counter_j, index))  # ccomp relation\n",
    "        check_conjunctions(ccomp_verbs, related_word, counter_j, index, dependencies, tokens_pos)\n",
    "\n",
    "    elif related_rel == 'parataxis':\n",
    "        parataxis_verbs.append((related_word, counter_j, index))  # parataxis relation\n",
    "        check_conjunctions(parataxis_verbs, related_word, counter_j, index, dependencies, tokens_pos)\n",
    "\n",
    "    elif related_rel == 'advcl':\n",
    "        advcl_verbs.append((related_word, counter_j, index))  # advcl relation\n",
    "        check_conjunctions(advcl_verbs, related_word, counter_j, index, dependencies, tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ea980d-d800-4637-a05c-79f56cda0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_one_function(row):\n",
    "    \"\"\"\n",
    "    Main function to find valid verbs (root, xcomp, ccomp, parataxis, advcl, and their conjunctions).\n",
    "    \"\"\"\n",
    "    dependencies = row['dependencies']  # Dependency relations for the sentence\n",
    "    tokens_pos = row['tokens_pos']  # POS-tagged tokens for the sentence\n",
    "\n",
    "    counter_i = 0  # Counter for tracking the index of words in the dependency structure\n",
    "    \n",
    "    # Lists to store categorized verbs\n",
    "    roots = []  # (word, own index, main root), if root is root (not conj) - write its own index\n",
    "    root_verbs = []  # For valid root verbs (that pass foreseeability and coercion checks)\n",
    "    xcomp_verbs = []  # For valid xcomp verbs\n",
    "    ccomp_verbs = []  # For valid ccomp verbs\n",
    "    parataxis_verbs = []  # For valid parataxis verbs\n",
    "    advcl_verbs = []  # For valid advcl verbs\n",
    "\n",
    "    # Iterate through dependencies to identify roots and their related verbs\n",
    "    for dep in dependencies:\n",
    "        if len(dep) == 3:\n",
    "            word, head, deprel = dep  # Unpacking the dependency tuple (word, head, relation)\n",
    "            counter_i += 1  # Increment the index counter for this word\n",
    "\n",
    "            # Reset counter when punctuation is found after root\n",
    "            if roots:\n",
    "                if deprel == 'punct' and (word == \".\" or word == \":\") and head == roots[0][1]:\n",
    "                    counter_i = 0  \n",
    "\n",
    "            # Check if the current word is the root of the sentence\n",
    "            if deprel == 'root':\n",
    "                roots.append((word, counter_i, counter_i))  # Add the root verb and its index\n",
    "                if is_valid_verb(word, tokens_pos):  # Check if the root is a valid verb\n",
    "                    root_verbs.append((word, counter_i, counter_i))  # Append valid root verb\n",
    "\n",
    "                # Looking for related conjunctions\n",
    "                counter_j = 0\n",
    "                for related in dependencies:\n",
    "                    if len(related) == 3:\n",
    "                        related_word, related_head, related_rel = related\n",
    "                        counter_j += 1  # Increment index for related word\n",
    "                        # Reset the counter for punctuation after root\n",
    "                        if related_rel == 'punct' and (related_word == \".\" or related_word == \":\") and related_head == roots[0][1]:\n",
    "                            counter_j = 0\n",
    "                        # Look for conjunctions attached to the root verb\n",
    "                        if related_head == counter_i and related_rel == 'conj' and is_valid_verb(related_word, tokens_pos):\n",
    "                            roots.append((related_word, counter_j, counter_i))  # Add root conj\n",
    "                            root_verbs.append((related_word, counter_j, counter_i))  # Append valid conj relation\n",
    "\n",
    "    # Find related verbs (xcomp, ccomp, etc.) for root verbs and their conjunctions\n",
    "    for verb in roots:\n",
    "        word, index, head_index = verb\n",
    "        counter_j = 0\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                counter_j += 1\n",
    "                # Reset the counter for punctuation after root\n",
    "                if related_rel == 'punct' and (related_word == \".\" or related_word == \":\") and related_head == roots[0][1]:\n",
    "                    counter_j = 0\n",
    "                # Handle xcomp, ccomp, parataxis, and advcl relations\n",
    "                if related_head == index and related_rel in ['xcomp', 'ccomp', 'parataxis', 'advcl'] and is_valid_verb(related_word, tokens_pos):\n",
    "                    handle_related_verbs(related_rel, related_word, counter_j, index, dependencies, tokens_pos, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs)\n",
    "\n",
    "    #print()\n",
    "    #print('NEW ROW')\n",
    "    #print('Valid root verbs: ', root_verbs)\n",
    "    #print('Valid xcomp verbs: ', xcomp_verbs)\n",
    "    #print('Valid ccomp verbs: ', ccomp_verbs)\n",
    "    #print('Valid parataxis verbs: ', parataxis_verbs)\n",
    "    #print('Valid advcl verbs: ', advcl_verbs)\n",
    "    \n",
    "    return roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30dbe389-4669-4a18-9135-f9128335f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_agent_validity(related_word, row, tokens_pos):\n",
    "    \"\"\"\n",
    "    Function to check the validity of an agent based on NER tags and additional rules.\n",
    "    \"\"\"\n",
    "    entities = row['entities']\n",
    "    valid_ent_labels = [\"PERSON\", \"NORP\", \"ORG\", \"GPE\"]\n",
    "    valid_additional_words = [\n",
    "        \"person\", \"man\", \"woman\", \"police\", \"administration\", \"immigrants\", \"president\", \"minister\", \"senator\", \"speaker\", \"secretary\", \"commissioner\", \"whip\",\n",
    "        \"representative\", \"governor\", \"mayor\", \"council\", \"secretary\", \"ambassador\", \"chancellor\", \"ministry\", \"monarchy\", \"diplomat\", \"chief\", \"legislator\",\n",
    "        \"parliamentary\", \"mr.\", \"ms.\", \"mrs.\", \"congressman\", \"congresswoman\", \"congress\", \"house\", \"member\", \"parliament\", \"judge\", \"attorney\", \"councillor\",\n",
    "        \"deputy\", \"candidate\", \"head\", \"lady\", \"gentleman\", \"advisor\", \"manager\", \"court\", \"prosecutor\", \"ombudsman\", \"inspector\", \"senate\", \"officer\"\n",
    "    ]\n",
    "\n",
    "    self = False\n",
    "    agent_is_valid = False\n",
    "    \n",
    "    # Original logic: Check if the related_word is a valid agent based on NER and additional terms\n",
    "    for entity, label in entities: \n",
    "        if related_word in entity and label in valid_ent_labels:  \n",
    "            agent_is_valid = True  # Valid agent based on NER\n",
    "    \n",
    "    # Check if it's a pronoun\n",
    "    if not agent_is_valid and 'PRON' in [pos for token, pos in tokens_pos if token == related_word]: \n",
    "        agent_is_valid = True  \n",
    "        # Logic for handling \"self\" reference (i.e., \"I\" or \"we\") - to be changed\n",
    "        #if related_word.lower() == \"i\" or related_word.lower() == \"we\":\n",
    "            #self = True\n",
    "\n",
    "    # Check if the word is in additional valid agent words\n",
    "    if not agent_is_valid and related_word.lower() in valid_additional_words:\n",
    "        agent_is_valid = True  \n",
    "    #if agent_is_valid:\n",
    "        #print(\"The Agent is valid: \", related_word)\n",
    "    \n",
    "    return agent_is_valid, self\n",
    "\n",
    "\n",
    "def check_causative_verb(verb):\n",
    "    \"\"\"\n",
    "    Function to check if the verb is causative, i.e., if it belongs to the 'cause' or 'CAUSETO' class.\n",
    "    \"\"\"\n",
    "    for synset in wn.synsets(verb, pos=wn.VERB):\n",
    "        if 'cause' in synset.lemma_names():\n",
    "            #print(\"found cause lemma\")\n",
    "            return True\n",
    "        for lemma in synset.lemmas():\n",
    "            for frame in lemma.frame_strings():\n",
    "                if 'CAUSE' in frame or 'CAUSETO' in frame:\n",
    "                    #print(\"found cause and causeto frame strings\")\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def define_polarity(verb, obj):\n",
    "    \"\"\"\n",
    "    Function to define the polarity of the verb + object combination.\n",
    "    Maybe use Word Sense Disambiguation (WSD) here?\n",
    "    \"\"\"\n",
    "    context = f\"{verb} {obj}\"\n",
    "    verb_sense = lesk(context.split(), verb, 'v')\n",
    "    obj_sense = lesk(context.split(), obj, 'n')\n",
    "    \n",
    "    pos_score = neg_score = 0\n",
    "    \n",
    "    if verb_sense:\n",
    "        swn_verb = swn.senti_synset(verb_sense.name())\n",
    "        pos_score += swn_verb.pos_score()\n",
    "        neg_score += swn_verb.neg_score()\n",
    "    \n",
    "    if obj_sense:\n",
    "        swn_obj = swn.senti_synset(obj_sense.name())\n",
    "        pos_score += swn_obj.pos_score()\n",
    "        neg_score += swn_obj.neg_score()\n",
    "\n",
    "    afinn_score = afinn.score(context)\n",
    "    if afinn_score > 0:\n",
    "        pos_score += afinn_score\n",
    "    else:\n",
    "        neg_score += abs(afinn_score)\n",
    "\n",
    "    subj_pos = sum([1 for token in context.split() if token in opinion_lexicon.positive()])\n",
    "    subj_neg = sum([1 for token in context.split() if token in opinion_lexicon.negative()])\n",
    "    \n",
    "    pos_score += subj_pos\n",
    "    neg_score += subj_neg\n",
    "\n",
    "    return 1 if pos_score > neg_score else 2 if neg_score > pos_score else 0\n",
    "\n",
    "\n",
    "def adjust_sentiment_for_negation(row, polarity, verb):\n",
    "    \"\"\"\n",
    "    Function to adjust the sentiment polarity for negation.\n",
    "    \"\"\"\n",
    "    word, index, head_index = verb\n",
    "    dependencies = row['dependencies']\n",
    "\n",
    "    for related in dependencies:\n",
    "        if len(related) == 3:\n",
    "            related_word, related_head, related_rel = related\n",
    "            if related_head == index and related_rel in ['advmod'] and (related_word == 'not' or related_word == 'n’t' or related_word == 'never'):\n",
    "                #print(\"Had found Negation\")\n",
    "                if polarity == 1:\n",
    "                    polarity = 2\n",
    "                    #print(\"Final Polarity: \", polarity)\n",
    "                    return polarity\n",
    "                if polarity == 2:\n",
    "                    polarity = 1\n",
    "                    #print(\"Final Polarity: \", polarity)\n",
    "                    return polarity\n",
    "\n",
    "    #print(\"Final Polarity: \", polarity)\n",
    "    \n",
    "    return polarity\n",
    "\n",
    "\n",
    "\n",
    "def handle_special_cases_for_xcomp_in_ccomp(row, verb, dependencies, tokens_pos, counter_j, related_word):\n",
    "    \"\"\"\n",
    "    Handle special cases for xcomp connected to ccomp, looking for objects connected to xcomp.\n",
    "    \n",
    "    for related_to_xcomp in dependencies:\n",
    "        if len(related_to_xcomp) == 3:\n",
    "            related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "            if related_to_xcomp_head == counter_j and related_to_xcomp_rel in ['obj']:\n",
    "                print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                # Define polarity of the combination xcomp + object\n",
    "                polarity = define_polarity(related_word, related_to_xcomp_word)\n",
    "                polarity = adjust_sentiment_for_negation(row, polarity, related_to_xcomp)\n",
    "                if polarity != 0:\n",
    "                    return polarity\n",
    "    for related_to_xcomp in dependencies:\n",
    "        if len(related_to_xcomp) == 3:\n",
    "            related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "            if related_to_xcomp_head == counter_j and related_to_xcomp_rel in ['iobj']:\n",
    "                print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                # Define polarity of the combination xcomp + object\n",
    "                polarity = define_polarity(related_word, related_to_xcomp_word)\n",
    "                polarity = adjust_sentiment_for_negation(row, polarity, related_to_xcomp)\n",
    "                if polarity != 0:\n",
    "                    return polarity\n",
    "    for related_to_xcomp in dependencies:\n",
    "        if len(related_to_xcomp) == 3:\n",
    "            related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "            if related_to_xcomp_head == counter_j and related_to_xcomp_rel in ['obl']:\n",
    "                print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                # Define polarity of the combination xcomp + object\n",
    "                polarity = define_polarity(related_word, related_to_xcomp_word)\n",
    "                polarity = adjust_sentiment_for_negation(row, polarity, related_to_xcomp)\n",
    "                if polarity != 0:\n",
    "                    return polarity\n",
    "\n",
    "    \"\"\"\n",
    "    for i, related in enumerate(dependencies):\n",
    "        if len(related) == 3:\n",
    "            related_word, related_head, related_rel = related\n",
    "            if related_head == verb[1] and related_rel in ['xcomp']:\n",
    "                #print(\"Found xcomp to ccomp: \", i, related_word, related_head, related_rel)\n",
    "                for related_to_xcomp in dependencies:\n",
    "                    if len(related) == 3:\n",
    "                        related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "                        # Maintain order of processing 'obj', 'iobj', and 'obl'\n",
    "                        if related_to_xcomp_head == (i+1) and related_to_xcomp_rel in ['obj']:\n",
    "                            polarity = define_polarity(verb[0], related_to_xcomp_word)\n",
    "                            #print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                            return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                for related_to_xcomp in dependencies:\n",
    "                    if len(related) == 3:\n",
    "                        related_word, related_head, related_rel = related_to_xcomp\n",
    "                        if related_to_xcomp_head == (i+1) and related_to_xcomp_rel in ['iobj']:\n",
    "                            polarity = define_polarity(verb[0], related_to_xcomp_word)\n",
    "                            #print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                            return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                for related_to_xcomp in dependencies:\n",
    "                    if len(related) == 3:\n",
    "                        related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "                        if related_to_xcomp_head == (i+1) and related_to_xcomp_rel in ['obl']:\n",
    "                            polarity = define_polarity(verb[0], related_to_xcomp_word)\n",
    "                            #print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                            return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_ccomp_verb(row, verb, dependencies, tokens_pos, roots):\n",
    "    \"\"\"\n",
    "    Process ccomp verbs and handle normal cases and special cases like `obl:agent` and `nsubj:pass`.\n",
    "    \"\"\"\n",
    "    word, index, head_index = verb\n",
    "    agent_is_valid, self = False, False\n",
    "    agent_is_obl = False  # Track if the agent comes from an `obl:agent`\n",
    "\n",
    "    # Find an agent connected to the ccomp verb (normal or obl:agent case)\n",
    "    for related in dependencies:\n",
    "        if len(related) == 3:\n",
    "            related_word, related_head, related_rel = related\n",
    "            # Check for `nsubj` as agent\n",
    "            if related_head == index and related_rel in ['nsubj']:\n",
    "                agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "\n",
    "            # Special case: `obl:agent` becomes the agent\n",
    "            elif related_head == index and related_rel in ['obl:agent', 'obl']:\n",
    "                agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "                agent_is_obl = True  # Mark that the agent is an `obl`\n",
    "\n",
    "    # If no valid agent, check for causative verbs\n",
    "    #if not agent_is_valid and check_causative_verb(word):\n",
    "        #agent_is_valid = True\n",
    "\n",
    "    # Object processing priority: `obj`, `iobj`\n",
    "    if agent_is_valid:\n",
    "        counter_j = 0\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                counter_j += 1\n",
    "                # Reset counter for punctuation\n",
    "                if related_rel == 'punct' and (related_word == \".\" or related_word == \":\") and related_head == roots[0][1]:\n",
    "                    counter_j = 0\n",
    "                \n",
    "                # Normal case: Handle objects connected to the ccomp verb\n",
    "                if related_head == index and related_rel in ['obj', 'iobj'] and not agent_is_obl:\n",
    "                    #print(\"The Object is valid: \", related_word)\n",
    "                    polarity = define_polarity(word, related_word)\n",
    "                    polarity = adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    if polarity != 0:\n",
    "                        #return f\"self - {polarity}\" if self else polarity\n",
    "                        return polarity, verb\n",
    "\n",
    "                # Special case: When `obl:agent` is present, `nsubj:pass` becomes the object\n",
    "                if agent_is_obl and related_head == index and related_rel == 'nsubj:pass':\n",
    "                    #print(\"The Object is valid: \", related_word)\n",
    "                    polarity = define_polarity(word, related_word)\n",
    "                    polarity = adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    if polarity != 0:\n",
    "                        #return f\"self - {polarity}\" if self else polarity, verb\n",
    "                        return polarity, verb\n",
    "\n",
    "                # Handle xcomp connected to ccomp and check objects within xcomp\n",
    "                polarity = handle_special_cases_for_xcomp_in_ccomp(row, verb, dependencies, tokens_pos, counter_j, related_word)\n",
    "                if polarity != 0:\n",
    "                    #return f\"self - {polarity}\" if self else polarity, verb\n",
    "                    return polarity, verb\n",
    "\n",
    "    return 0, None\n",
    "\n",
    "\n",
    "\n",
    "def find_object_and_define_polarity(row, verb, agent_is_valid, tokens_pos):\n",
    "    \"\"\"\n",
    "    Helper function to find the object for a given verb and define its polarity.\n",
    "    \"\"\"\n",
    "    if agent_is_valid:\n",
    "        dependencies = row['dependencies']\n",
    "\n",
    "        # xcomp case\n",
    "        for i, related in enumerate(dependencies):\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                if related_head == verb[1] and related_rel in ['xcomp']:\n",
    "                    #print(\"Found xcomp to ccomp: \", i, related_word, related_head, related_rel)\n",
    "                    for related_to_xcomp in dependencies:\n",
    "                        if len(related) == 3:\n",
    "                            related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "                            # Maintain order of processing 'obj', 'iobj', and 'obl'\n",
    "                            if related_to_xcomp_head == (i+1) and related_to_xcomp_rel in ['obj']:\n",
    "                                polarity = define_polarity(verb[0], related_to_xcomp_word)\n",
    "                                #print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                                return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    for related_to_xcomp in dependencies:\n",
    "                        if len(related) == 3:\n",
    "                            related_word, related_head, related_rel = related_to_xcomp\n",
    "                            if related_to_xcomp_head == (i+1) and related_to_xcomp_rel in ['iobj']:\n",
    "                                polarity = define_polarity(verb[0], related_to_xcomp_word)\n",
    "                                #print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                                return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    for related_to_xcomp in dependencies:\n",
    "                        if len(related) == 3:\n",
    "                            related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "                            if related_to_xcomp_head == (i+1) and related_to_xcomp_rel in ['obl']:\n",
    "                                polarity = define_polarity(verb[0], related_to_xcomp_word)\n",
    "                                #print(\"The Object is valid: \", related_to_xcomp_word)\n",
    "                                return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "        \n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                # Maintain order of processing 'obj', 'iobj', and 'obl'\n",
    "                if related_head == verb[1] and related_rel in ['obj']:\n",
    "                    polarity = define_polarity(verb[0], related_word)\n",
    "                    #print(\"The Object is valid: \", related_word)\n",
    "                    return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                if related_head == verb[1] and related_rel in ['iobj']:\n",
    "                    polarity = define_polarity(verb[0], related_word)\n",
    "                    #print(\"The Object is valid: \", related_word)\n",
    "                    return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                if related_head == verb[1] and related_rel in ['obl']:\n",
    "                    polarity = define_polarity(verb[0], related_word)\n",
    "                    #print(\"The Object is valid: \", related_word)\n",
    "                    return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    \n",
    "        # Handle objects connected to xcomp\n",
    "        #polarity = handle_special_cases_for_xcomp_in_ccomp(row, verb, dependencies, tokens_pos, counter_j, related_word)\n",
    "        #if polarity != 0:\n",
    "            #return f\"self - {polarity}\" if self else polarity\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def process_verb_connections(row, verbs, tokens_pos, self=False):\n",
    "    \"\"\"\n",
    "    Generalized function to process verb connections such as root_verbs, xcomp_verbs, etc.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    for verb in verbs:\n",
    "        word, index, head_index = verb\n",
    "        agent_is_valid = False\n",
    "\n",
    "        # Original logic for agent validation\n",
    "        for related in row['dependencies']:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                #if related_head == index and related_rel in ['nsubj', 'nsubj:pass']:\n",
    "                if related_head == index and related_rel in ['nsubj']:\n",
    "                    agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "                else:\n",
    "                    # Checking if the agent of the root of that verb is valid\n",
    "                    if related_head == head_index and related_rel in ['nsubj']: \n",
    "                        agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "        \n",
    "        # If agent is not valid, check causative verb\n",
    "        #if not agent_is_valid and check_causative_verb(word):\n",
    "            #agent_is_valid = True\n",
    "\n",
    "        # Use original priority order for object detection\n",
    "        polarity = find_object_and_define_polarity(row, verb, agent_is_valid, tokens_pos)\n",
    "        if polarity != 0:\n",
    "            #return f\"self - {polarity}\" if self else polarity, verb\n",
    "            return polarity, verb\n",
    "\n",
    "    return result, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01c3852-ef74-496c-aeb5-95f01c929ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_two_function(row, roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs):\n",
    "    \"\"\"\n",
    "    Main function to decide on Agent Causality, find the object, decide on Polarity, and classify the row.\n",
    "    \"\"\"\n",
    "    tokens_pos = row['tokens_pos']\n",
    "    dependencies = row['dependencies']\n",
    "\n",
    "    result, verb = process_verb_connections(row, root_verbs, tokens_pos)\n",
    "    if result:\n",
    "        if result == 1 or result == 2:\n",
    "            #print(verb)\n",
    "            return result, verb\n",
    "        return result, None\n",
    "        \n",
    "    # Process ccomp verbs with priority handling and special cases\n",
    "    for verb in ccomp_verbs:\n",
    "        result, verb = process_ccomp_verb(row, verb, dependencies, tokens_pos, roots)\n",
    "        if result:\n",
    "            if result == 1 or result == 2:\n",
    "                #print(verb)\n",
    "                return result, verb\n",
    "            return result, None\n",
    "\n",
    "    # Process advcl verbs\n",
    "    result, verb = process_verb_connections(row, advcl_verbs, tokens_pos)\n",
    "    if result:\n",
    "        if result == 1 or result == 2:\n",
    "            #print(verb)\n",
    "            return result, verb\n",
    "        return result, None\n",
    "        \n",
    "    # Process parataxis verbs\n",
    "    result, verb = process_verb_connections(row, parataxis_verbs, tokens_pos)\n",
    "    if result:\n",
    "        if result == 1 or result == 2:\n",
    "            #print(verb)\n",
    "            return result, verb\n",
    "        return result, None\n",
    "    \n",
    "    # Process xcomp verbs\n",
    "    result, verb = process_verb_connections(row, xcomp_verbs, tokens_pos)\n",
    "    if result:\n",
    "        if result == 1 or result == 2:\n",
    "            #print(verb)\n",
    "            return result, verb\n",
    "        return result, None\n",
    "\n",
    "    return 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e4e0cf-d699-42a2-968b-063783d3a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_the_row(row):\n",
    "    result = 0\n",
    "    # This is the main function to process each row of data and classify the row \n",
    "\n",
    "    # 1 - Find all the related verbs in categories in dependency column 'root', 'xcomp', 'ccomp', 'parataxis', 'advcl', 'conj' (is a verb check - foreseeability check - coercion check)\n",
    "    roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs = step_one_function(row)\n",
    "    \n",
    "    # 2 - If at least one of the lists is not empty - can proceed\n",
    "    if root_verbs or xcomp_verbs or ccomp_verbs or parataxis_verbs or advcl_verbs:\n",
    "        \n",
    "        # 3 - Take a final decision about the label (0 - others, 1 - positive, 2 - negative)\n",
    "        return step_two_function(row, roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs)\n",
    "    \n",
    "    else:\n",
    "        return 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cab18c-a926-44bd-a1ef-2ba42452f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wrapper function to handle errors and log the row that causes the issue\n",
    "def safe_label_the_row(row):\n",
    "    try:\n",
    "        # Call the label_the_row function\n",
    "        return label_the_row(row)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in row {row['Sentence']}: {e}\")\n",
    "        return None, None  # Return default values when there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2610d12-2d89-4045-be0c-7457f407cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function with error handling\n",
    "shuffled_df['Final_Result'], shuffled_df['Event_Verb'] = zip(*shuffled_df.apply(safe_label_the_row, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0885035a-60a6-455b-8a9b-3f963f9dc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffled_df['Final_Result'], shuffled_df['Event_Verb'] = shuffled_df.apply(label_the_row, axis=1)\n",
    "shuffled_df = shuffled_df[['Sentence', 'Label', 'Final_Result', 'Event_Verb'] + [col for col in shuffled_df.columns if col not in ['Sentence', 'Label', 'Final_Result', 'Event_Verb']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19448ab3-75b8-4765-81f4-a7faf19cea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Final_Result</th>\n",
       "      <th>Event_Verb</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The faculty's Academic Senate threw its suppor...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(threw, 6, 6)</td>\n",
       "      <td>[(The, DET), (faculty, NOUN), ('s, PART), (Aca...</td>\n",
       "      <td>[(Academic Senate, ORG), (Monday, DATE), (the ...</td>\n",
       "      <td>[(The, 2, det), (faculty, 5, nmod:poss), ('s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But the true scale of the movement remains unc...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(But, CCONJ), (the, DET), (true, ADJ), (scale...</td>\n",
       "      <td>[(Miskito, NORP), (Nicaraguan, NORP)]</td>\n",
       "      <td>[(But, 8, cc), (the, 4, det), (true, 4, amod),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Branstad is ripping Cruz for taking the bold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(ripping, 4, 4)</td>\n",
       "      <td>[((, PUNCT), (Branstad, PROPN), (is, AUX), (ri...</td>\n",
       "      <td>[(Branstad, PERSON), (Cruz, PERSON), (Iowa, GPE)]</td>\n",
       "      <td>[((, 4, punct), (Branstad, 4, nsubj), (is, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But the Marlins have failed to make the postse...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(failed, 5, 5)</td>\n",
       "      <td>[(But, CCONJ), (the, DET), (Marlins, PROPN), (...</td>\n",
       "      <td>[(Marlins, ORG), (Loria, PERSON)]</td>\n",
       "      <td>[(But, 5, cc), (the, 3, det), (Marlins, 5, nsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is nothing new yet on the table, but one...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(There, PRON), (is, VERB), (nothing, PRON), (...</td>\n",
       "      <td>[(one, CARDINAL), (Gannett, ORG), (Tribune Pub...</td>\n",
       "      <td>[(There, 2, expl), (is, 0, root), (nothing, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>Conservatives have sided with government moves...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>(expel, 8, 3)</td>\n",
       "      <td>[(Conservatives, PROPN), (have, AUX), (sided, ...</td>\n",
       "      <td>[(Conservatives, NORP), (Shin, PERSON), (North...</td>\n",
       "      <td>[(Conservatives, 3, nsubj), (have, 3, aux), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>However, former prosecutor Andrew McCarthy, no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(However, ADV), (,, PUNCT), (former, ADJ), (p...</td>\n",
       "      <td>[(Andrew McCarthy, PERSON), (National Review, ...</td>\n",
       "      <td>[(However, 15, advmod), (,, 1, punct), (former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>Dunham’s accusing the left of “hostility” and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(accusing, 3, 3)</td>\n",
       "      <td>[(Dunham, PROPN), (’s, AUX), (accusing, VERB),...</td>\n",
       "      <td>[(Dunham’s, PERSON), (thousands, CARDINAL), (T...</td>\n",
       "      <td>[(Dunham, 3, nsubj), (’s, 3, aux), (accusing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>In the aftermath of the attack, Thoiry is warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(warning, 10, 10)</td>\n",
       "      <td>[(In, ADP), (the, DET), (aftermath, NOUN), (of...</td>\n",
       "      <td>[(Thoiry, PERSON), (European, NORP)]</td>\n",
       "      <td>[(In, 3, case), (the, 3, det), (aftermath, 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Guillermo Lasso, the losing conservative candi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Guillermo, PROPN), (Lasso, PROPN), (,, PUNCT...</td>\n",
       "      <td>[(Guillermo Lasso, PERSON), (24, CARDINAL)]</td>\n",
       "      <td>[(Guillermo, 9, nsubj), (Lasso, 1, flat), (,, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6227 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Label  Final_Result  \\\n",
       "0     The faculty's Academic Senate threw its suppor...      0             1   \n",
       "1     But the true scale of the movement remains unc...      2             0   \n",
       "2     (Branstad is ripping Cruz for taking the bold ...      0             2   \n",
       "3     But the Marlins have failed to make the postse...      0             2   \n",
       "4     There is nothing new yet on the table, but one...      1             0   \n",
       "...                                                 ...    ...           ...   \n",
       "6222  Conservatives have sided with government moves...      2             2   \n",
       "6223  However, former prosecutor Andrew McCarthy, no...      0             0   \n",
       "6224  Dunham’s accusing the left of “hostility” and ...      0             2   \n",
       "6225  In the aftermath of the attack, Thoiry is warn...      0             2   \n",
       "6226  Guillermo Lasso, the losing conservative candi...      2             0   \n",
       "\n",
       "             Event_Verb                                         tokens_pos  \\\n",
       "0         (threw, 6, 6)  [(The, DET), (faculty, NOUN), ('s, PART), (Aca...   \n",
       "1                  None  [(But, CCONJ), (the, DET), (true, ADJ), (scale...   \n",
       "2       (ripping, 4, 4)  [((, PUNCT), (Branstad, PROPN), (is, AUX), (ri...   \n",
       "3        (failed, 5, 5)  [(But, CCONJ), (the, DET), (Marlins, PROPN), (...   \n",
       "4                  None  [(There, PRON), (is, VERB), (nothing, PRON), (...   \n",
       "...                 ...                                                ...   \n",
       "6222      (expel, 8, 3)  [(Conservatives, PROPN), (have, AUX), (sided, ...   \n",
       "6223               None  [(However, ADV), (,, PUNCT), (former, ADJ), (p...   \n",
       "6224   (accusing, 3, 3)  [(Dunham, PROPN), (’s, AUX), (accusing, VERB),...   \n",
       "6225  (warning, 10, 10)  [(In, ADP), (the, DET), (aftermath, NOUN), (of...   \n",
       "6226               None  [(Guillermo, PROPN), (Lasso, PROPN), (,, PUNCT...   \n",
       "\n",
       "                                               entities  \\\n",
       "0     [(Academic Senate, ORG), (Monday, DATE), (the ...   \n",
       "1                 [(Miskito, NORP), (Nicaraguan, NORP)]   \n",
       "2     [(Branstad, PERSON), (Cruz, PERSON), (Iowa, GPE)]   \n",
       "3                     [(Marlins, ORG), (Loria, PERSON)]   \n",
       "4     [(one, CARDINAL), (Gannett, ORG), (Tribune Pub...   \n",
       "...                                                 ...   \n",
       "6222  [(Conservatives, NORP), (Shin, PERSON), (North...   \n",
       "6223  [(Andrew McCarthy, PERSON), (National Review, ...   \n",
       "6224  [(Dunham’s, PERSON), (thousands, CARDINAL), (T...   \n",
       "6225               [(Thoiry, PERSON), (European, NORP)]   \n",
       "6226        [(Guillermo Lasso, PERSON), (24, CARDINAL)]   \n",
       "\n",
       "                                           dependencies  \n",
       "0     [(The, 2, det), (faculty, 5, nmod:poss), ('s, ...  \n",
       "1     [(But, 8, cc), (the, 4, det), (true, 4, amod),...  \n",
       "2     [((, 4, punct), (Branstad, 4, nsubj), (is, 4, ...  \n",
       "3     [(But, 5, cc), (the, 3, det), (Marlins, 5, nsu...  \n",
       "4     [(There, 2, expl), (is, 0, root), (nothing, 2,...  \n",
       "...                                                 ...  \n",
       "6222  [(Conservatives, 3, nsubj), (have, 3, aux), (s...  \n",
       "6223  [(However, 15, advmod), (,, 1, punct), (former...  \n",
       "6224  [(Dunham, 3, nsubj), (’s, 3, aux), (accusing, ...  \n",
       "6225  [(In, 3, case), (the, 3, det), (aftermath, 10,...  \n",
       "6226  [(Guillermo, 9, nsubj), (Lasso, 1, flat), (,, ...  \n",
       "\n",
       "[6227 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "915deb00-52fe-4572-b9e7-5a7f68e35cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Result\n",
       "0    4242\n",
       "2    1103\n",
       "1     882\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['Final_Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "826b0b37-191c-49ff-b5ee-d3e738112274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['Final_Result'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80232b5-0c37-466e-9c42-8022250cea6e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81a296a3-fa30-49fa-a7f1-701772bc3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels and predicted labels\n",
    "y_true = shuffled_df['Label']\n",
    "y_pred = shuffled_df['Final_Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29b674ec-f8c7-4c94-a771-73660a1670f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric  Micro-average  Macro-average  Weighted-average\n",
      "0   F1 Score       0.574434       0.491822          0.556432\n",
      "1  Precision       0.574434       0.524189               NaN\n",
      "2     Recall       0.574434       0.485881               NaN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68      3390\n",
      "           1       0.39      0.35      0.37       969\n",
      "           2       0.57      0.34      0.43      1868\n",
      "\n",
      "    accuracy                           0.57      6227\n",
      "   macro avg       0.52      0.49      0.49      6227\n",
      "weighted avg       0.57      0.57      0.56      6227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame with 'Label' as true labels and 'Final_Result' as predicted labels\n",
    "\n",
    "# Calculate F1 Scores\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Calculate Precision and Recall for completeness (optional)\n",
    "precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "precision_macro = precision_score(y_true, y_pred, average='macro')\n",
    "recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['F1 Score', 'Precision', 'Recall'],\n",
    "    'Micro-average': [f1_micro, precision_micro, recall_micro],\n",
    "    'Macro-average': [f1_macro, precision_macro, recall_macro],\n",
    "    'Weighted-average': [f1_weighted, None, None]  # Weighted average only applicable to F1 score here\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(results_df)\n",
    "\n",
    "# You can also use classification report to see more detailed metrics\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d673a-c154-41a3-ad5d-226a369954f0",
   "metadata": {},
   "source": [
    "# Export in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828b8147-936a-466b-8c3d-22810ed6440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the first 300 rows to an Excel file\n",
    "#shuffled_df.head(100).to_excel('shuffled_df_new_100_rows.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9537f-183b-4efd-90a3-5c31377c9269",
   "metadata": {},
   "source": [
    "# False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2b3384a-2c8e-460e-b6d7-5e53d0dc53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive: Label is 0, but Final_Result is 1 or 2\n",
    "false_positives = shuffled_df[(shuffled_df['Label'] == 0) & (shuffled_df['Final_Result'].isin([1, 2]))]\n",
    "\n",
    "# Count the number of false positives\n",
    "false_positive_count = false_positives.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0321d471-db18-4388-804c-147161e39d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Final_Result</th>\n",
       "      <th>Event_Verb</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The faculty's Academic Senate threw its suppor...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(threw, 6, 6)</td>\n",
       "      <td>[(The, DET), (faculty, NOUN), ('s, PART), (Aca...</td>\n",
       "      <td>[(Academic Senate, ORG), (Monday, DATE), (the ...</td>\n",
       "      <td>[(The, 2, det), (faculty, 5, nmod:poss), ('s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Branstad is ripping Cruz for taking the bold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(ripping, 4, 4)</td>\n",
       "      <td>[((, PUNCT), (Branstad, PROPN), (is, AUX), (ri...</td>\n",
       "      <td>[(Branstad, PERSON), (Cruz, PERSON), (Iowa, GPE)]</td>\n",
       "      <td>[((, 4, punct), (Branstad, 4, nsubj), (is, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But the Marlins have failed to make the postse...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(failed, 5, 5)</td>\n",
       "      <td>[(But, CCONJ), (the, DET), (Marlins, PROPN), (...</td>\n",
       "      <td>[(Marlins, ORG), (Loria, PERSON)]</td>\n",
       "      <td>[(But, 5, cc), (the, 3, det), (Marlins, 5, nsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aside from the 22 endorsements thus far, Clint...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(continue, 15, 12)</td>\n",
       "      <td>[(Aside, ADV), (from, ADP), (the, DET), (22, N...</td>\n",
       "      <td>[(22, CARDINAL), (Clinton, PERSON), (GOP, ORG)...</td>\n",
       "      <td>[(Aside, 12, advmod), (from, 5, case), (the, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Statistically, Kaepernick has been better than...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(playing, 17, 6)</td>\n",
       "      <td>[(Statistically, ADV), (,, PUNCT), (Kaepernick...</td>\n",
       "      <td>[(Kaepernick, PERSON), (Ravens, ORG), (the las...</td>\n",
       "      <td>[(Statistically, 6, advmod), (,, 6, punct), (K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>The future, AQAP’s fortunes will in great part...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(falls, 18, 11)</td>\n",
       "      <td>[(The, DET), (future, NOUN), (,, PUNCT), (AQAP...</td>\n",
       "      <td>[(Yemen, GPE)]</td>\n",
       "      <td>[(The, 2, det), (future, 11, nsubj), (,, 2, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>Prime Minister David Cameron gathered world le...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(crack, 12, 5)</td>\n",
       "      <td>[(Prime, ADJ), (Minister, PROPN), (David, PROP...</td>\n",
       "      <td>[(David Cameron, PERSON), (London, GPE), (Thur...</td>\n",
       "      <td>[(Prime, 2, amod), (Minister, 5, nsubj), (Davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>The future, AQAP’s fortunes will in great part...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(falls, 18, 11)</td>\n",
       "      <td>[(The, DET), (future, NOUN), (,, PUNCT), (AQAP...</td>\n",
       "      <td>[(Yemen, GPE)]</td>\n",
       "      <td>[(The, 2, det), (future, 11, nsubj), (,, 2, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>Dunham’s accusing the left of “hostility” and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(accusing, 3, 3)</td>\n",
       "      <td>[(Dunham, PROPN), (’s, AUX), (accusing, VERB),...</td>\n",
       "      <td>[(Dunham’s, PERSON), (thousands, CARDINAL), (T...</td>\n",
       "      <td>[(Dunham, 3, nsubj), (’s, 3, aux), (accusing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>In the aftermath of the attack, Thoiry is warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(warning, 10, 10)</td>\n",
       "      <td>[(In, ADP), (the, DET), (aftermath, NOUN), (of...</td>\n",
       "      <td>[(Thoiry, PERSON), (European, NORP)]</td>\n",
       "      <td>[(In, 3, case), (the, 3, det), (aftermath, 10,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Label  Final_Result  \\\n",
       "0     The faculty's Academic Senate threw its suppor...      0             1   \n",
       "2     (Branstad is ripping Cruz for taking the bold ...      0             2   \n",
       "3     But the Marlins have failed to make the postse...      0             2   \n",
       "7     Aside from the 22 endorsements thus far, Clint...      0             1   \n",
       "10    Statistically, Kaepernick has been better than...      0             1   \n",
       "...                                                 ...    ...           ...   \n",
       "6209  The future, AQAP’s fortunes will in great part...      0             2   \n",
       "6212  Prime Minister David Cameron gathered world le...      0             2   \n",
       "6214  The future, AQAP’s fortunes will in great part...      0             2   \n",
       "6224  Dunham’s accusing the left of “hostility” and ...      0             2   \n",
       "6225  In the aftermath of the attack, Thoiry is warn...      0             2   \n",
       "\n",
       "              Event_Verb                                         tokens_pos  \\\n",
       "0          (threw, 6, 6)  [(The, DET), (faculty, NOUN), ('s, PART), (Aca...   \n",
       "2        (ripping, 4, 4)  [((, PUNCT), (Branstad, PROPN), (is, AUX), (ri...   \n",
       "3         (failed, 5, 5)  [(But, CCONJ), (the, DET), (Marlins, PROPN), (...   \n",
       "7     (continue, 15, 12)  [(Aside, ADV), (from, ADP), (the, DET), (22, N...   \n",
       "10      (playing, 17, 6)  [(Statistically, ADV), (,, PUNCT), (Kaepernick...   \n",
       "...                  ...                                                ...   \n",
       "6209     (falls, 18, 11)  [(The, DET), (future, NOUN), (,, PUNCT), (AQAP...   \n",
       "6212      (crack, 12, 5)  [(Prime, ADJ), (Minister, PROPN), (David, PROP...   \n",
       "6214     (falls, 18, 11)  [(The, DET), (future, NOUN), (,, PUNCT), (AQAP...   \n",
       "6224    (accusing, 3, 3)  [(Dunham, PROPN), (’s, AUX), (accusing, VERB),...   \n",
       "6225   (warning, 10, 10)  [(In, ADP), (the, DET), (aftermath, NOUN), (of...   \n",
       "\n",
       "                                               entities  \\\n",
       "0     [(Academic Senate, ORG), (Monday, DATE), (the ...   \n",
       "2     [(Branstad, PERSON), (Cruz, PERSON), (Iowa, GPE)]   \n",
       "3                     [(Marlins, ORG), (Loria, PERSON)]   \n",
       "7     [(22, CARDINAL), (Clinton, PERSON), (GOP, ORG)...   \n",
       "10    [(Kaepernick, PERSON), (Ravens, ORG), (the las...   \n",
       "...                                                 ...   \n",
       "6209                                     [(Yemen, GPE)]   \n",
       "6212  [(David Cameron, PERSON), (London, GPE), (Thur...   \n",
       "6214                                     [(Yemen, GPE)]   \n",
       "6224  [(Dunham’s, PERSON), (thousands, CARDINAL), (T...   \n",
       "6225               [(Thoiry, PERSON), (European, NORP)]   \n",
       "\n",
       "                                           dependencies  \n",
       "0     [(The, 2, det), (faculty, 5, nmod:poss), ('s, ...  \n",
       "2     [((, 4, punct), (Branstad, 4, nsubj), (is, 4, ...  \n",
       "3     [(But, 5, cc), (the, 3, det), (Marlins, 5, nsu...  \n",
       "7     [(Aside, 12, advmod), (from, 5, case), (the, 5...  \n",
       "10    [(Statistically, 6, advmod), (,, 6, punct), (K...  \n",
       "...                                                 ...  \n",
       "6209  [(The, 2, det), (future, 11, nsubj), (,, 2, pu...  \n",
       "6212  [(Prime, 2, amod), (Minister, 5, nsubj), (Davi...  \n",
       "6214  [(The, 2, det), (future, 11, nsubj), (,, 2, pu...  \n",
       "6224  [(Dunham, 3, nsubj), (’s, 3, aux), (accusing, ...  \n",
       "6225  [(In, 3, case), (the, 3, det), (aftermath, 10,...  \n",
       "\n",
       "[785 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67af30fc-adac-4ce5-b631-060dcc338294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4feb3022-b7ac-49e0-9391-46da61dfc737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1260639152079653"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_count/shuffled_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05b371-3e45-444d-a74d-2194914287be",
   "metadata": {},
   "source": [
    "# Verb Do and its variations as a Valid Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9588c17e-de28-4496-a7cb-6beb52cb58bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('did', 5, 5)\n",
      "('doing', 6, 6)\n",
      "('doing', 9, 4)\n",
      "('doing', 9, 4)\n",
      "('doing', 6, 6)\n",
      "('does', 17, 17)\n",
      "('do', 6, 6)\n",
      "('did', 5, 5)\n",
      "('does', 8, 3)\n",
      "('does', 8, 3)\n",
      "('does', 17, 17)\n",
      "('does', 5, 5)\n",
      "('done', 3, 3)\n",
      "('does', 3, 5)\n",
      "('doing', 11, 7)\n",
      "('do', 7, 3)\n",
      "('does', 7, 4)\n",
      "('did', 10, 2)\n",
      "('did', 5, 5)\n",
      "('do', 6, 2)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for verb in shuffled_df['Event_Verb']:\n",
    "    if verb:\n",
    "        if verb[0] in ['do', 'does', 'did', 'done', 'doing']:\n",
    "            counter = counter + 1\n",
    "            print(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eca30dd9-0204-44b6-883a-a3485198d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03f64a2c-b3c4-4b69-981c-8cbb44c82df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003211819495744339"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter / shuffled_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2cfb9-8912-4859-b614-ecaf4f782d73",
   "metadata": {},
   "source": [
    "# Checking Labels of None in column Event_Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe76ab03-3692-47af-ae2b-219c3ded1a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows_with_none = shuffled_df[shuffled_df['Event_Verb'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a579d79c-9dfa-44b4-9af9-83230b7ccf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Final_Result</th>\n",
       "      <th>Event_Verb</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But the true scale of the movement remains unc...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(But, CCONJ), (the, DET), (true, ADJ), (scale...</td>\n",
       "      <td>[(Miskito, NORP), (Nicaraguan, NORP)]</td>\n",
       "      <td>[(But, 8, cc), (the, 4, det), (true, 4, amod),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is nothing new yet on the table, but one...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(There, PRON), (is, VERB), (nothing, PRON), (...</td>\n",
       "      <td>[(one, CARDINAL), (Gannett, ORG), (Tribune Pub...</td>\n",
       "      <td>[(There, 2, expl), (is, 0, root), (nothing, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Former Assistant U. S. Attorney Reed Brodsky, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Former, ADJ), (Assistant, PROPN), (U., PROPN...</td>\n",
       "      <td>[(Reed Brodsky, PERSON), (Dowd, PERSON)]</td>\n",
       "      <td>[(Former, 5, amod), (Assistant, 5, compound), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The speedy Manchester United forward lavishly ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(The, DET), (speedy, ADJ), (Manchester, PROPN...</td>\n",
       "      <td>[(Manchester United, GPE), (two, CARDINAL), (H...</td>\n",
       "      <td>[(The, 5, det), (speedy, 5, amod), (Manchester...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Similarly, some Republican strategists will co...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Similarly, ADV), (,, PUNCT), (some, DET), (R...</td>\n",
       "      <td>[(Republican, NORP), (Obama, PERSON), (the Dem...</td>\n",
       "      <td>[(Similarly, 7, advmod), (,, 7, punct), (some,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>Fallout over the abuse allegations against Joh...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Fallout, NOUN), (over, ADP), (the, DET), (ab...</td>\n",
       "      <td>[(Johnny Depp, PERSON), (Amber Heard, PERSON),...</td>\n",
       "      <td>[(Fallout, 19, nsubj), (over, 5, case), (the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>Since North Carolina Gov. Pat McCrory last wee...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Since, SCONJ), (North, PROPN), (Carolina, PR...</td>\n",
       "      <td>[(North Carolina, GPE), (Pat McCrory, PERSON),...</td>\n",
       "      <td>[(Since, 9, mark), (North, 3, compound), (Caro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>Herman Cain and Newt Gingrich, the living embo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Herman, PROPN), (Cain, PROPN), (and, CCONJ),...</td>\n",
       "      <td>[(Herman Cain, PERSON), (Newt Gingrich, PERSON...</td>\n",
       "      <td>[(Herman, 35, nsubj), (Cain, 1, flat), (and, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>However, former prosecutor Andrew McCarthy, no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(However, ADV), (,, PUNCT), (former, ADJ), (p...</td>\n",
       "      <td>[(Andrew McCarthy, PERSON), (National Review, ...</td>\n",
       "      <td>[(However, 15, advmod), (,, 1, punct), (former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Guillermo Lasso, the losing conservative candi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[(Guillermo, PROPN), (Lasso, PROPN), (,, PUNCT...</td>\n",
       "      <td>[(Guillermo Lasso, PERSON), (24, CARDINAL)]</td>\n",
       "      <td>[(Guillermo, 9, nsubj), (Lasso, 1, flat), (,, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4242 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Label  Final_Result  \\\n",
       "1     But the true scale of the movement remains unc...      2             0   \n",
       "4     There is nothing new yet on the table, but one...      1             0   \n",
       "5     Former Assistant U. S. Attorney Reed Brodsky, ...      2             0   \n",
       "9     The speedy Manchester United forward lavishly ...      1             0   \n",
       "11    Similarly, some Republican strategists will co...      2             0   \n",
       "...                                                 ...    ...           ...   \n",
       "6218  Fallout over the abuse allegations against Joh...      2             0   \n",
       "6219  Since North Carolina Gov. Pat McCrory last wee...      2             0   \n",
       "6220  Herman Cain and Newt Gingrich, the living embo...      0             0   \n",
       "6223  However, former prosecutor Andrew McCarthy, no...      0             0   \n",
       "6226  Guillermo Lasso, the losing conservative candi...      2             0   \n",
       "\n",
       "     Event_Verb                                         tokens_pos  \\\n",
       "1          None  [(But, CCONJ), (the, DET), (true, ADJ), (scale...   \n",
       "4          None  [(There, PRON), (is, VERB), (nothing, PRON), (...   \n",
       "5          None  [(Former, ADJ), (Assistant, PROPN), (U., PROPN...   \n",
       "9          None  [(The, DET), (speedy, ADJ), (Manchester, PROPN...   \n",
       "11         None  [(Similarly, ADV), (,, PUNCT), (some, DET), (R...   \n",
       "...         ...                                                ...   \n",
       "6218       None  [(Fallout, NOUN), (over, ADP), (the, DET), (ab...   \n",
       "6219       None  [(Since, SCONJ), (North, PROPN), (Carolina, PR...   \n",
       "6220       None  [(Herman, PROPN), (Cain, PROPN), (and, CCONJ),...   \n",
       "6223       None  [(However, ADV), (,, PUNCT), (former, ADJ), (p...   \n",
       "6226       None  [(Guillermo, PROPN), (Lasso, PROPN), (,, PUNCT...   \n",
       "\n",
       "                                               entities  \\\n",
       "1                 [(Miskito, NORP), (Nicaraguan, NORP)]   \n",
       "4     [(one, CARDINAL), (Gannett, ORG), (Tribune Pub...   \n",
       "5              [(Reed Brodsky, PERSON), (Dowd, PERSON)]   \n",
       "9     [(Manchester United, GPE), (two, CARDINAL), (H...   \n",
       "11    [(Republican, NORP), (Obama, PERSON), (the Dem...   \n",
       "...                                                 ...   \n",
       "6218  [(Johnny Depp, PERSON), (Amber Heard, PERSON),...   \n",
       "6219  [(North Carolina, GPE), (Pat McCrory, PERSON),...   \n",
       "6220  [(Herman Cain, PERSON), (Newt Gingrich, PERSON...   \n",
       "6223  [(Andrew McCarthy, PERSON), (National Review, ...   \n",
       "6226        [(Guillermo Lasso, PERSON), (24, CARDINAL)]   \n",
       "\n",
       "                                           dependencies  \n",
       "1     [(But, 8, cc), (the, 4, det), (true, 4, amod),...  \n",
       "4     [(There, 2, expl), (is, 0, root), (nothing, 2,...  \n",
       "5     [(Former, 5, amod), (Assistant, 5, compound), ...  \n",
       "9     [(The, 5, det), (speedy, 5, amod), (Manchester...  \n",
       "11    [(Similarly, 7, advmod), (,, 7, punct), (some,...  \n",
       "...                                                 ...  \n",
       "6218  [(Fallout, 19, nsubj), (over, 5, case), (the, ...  \n",
       "6219  [(Since, 9, mark), (North, 3, compound), (Caro...  \n",
       "6220  [(Herman, 35, nsubj), (Cain, 1, flat), (and, 4...  \n",
       "6223  [(However, 15, advmod), (,, 1, punct), (former...  \n",
       "6226  [(Guillermo, 9, nsubj), (Lasso, 1, flat), (,, ...  \n",
       "\n",
       "[4242 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8edb08cf-7d86-41a5-8a39-848bcfbed02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Result\n",
       "0    4242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_none[\"Final_Result\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75d191-4734-4557-998b-52562a54bc63",
   "metadata": {},
   "source": [
    "**So everything is correct - if no valid Verb found -> label 0 (neutral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cb905-4eb9-4630-acd1-b2968d46b6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb610b-c27c-4f71-bdf7-c618f4c397ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed3352-db5e-4d6e-833a-eabfaf169716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6aa51dcb-9bd7-4adc-af2d-90655ed7b59d",
    "5b4b9a5d-f5f1-4b41-89b1-ef0f7ec9269b",
    "XgpcdWkBTA2i"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0489b43fc7e64734882843d7d1dbccce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d91f88d2bd41c2911b27882b1bc3c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fb17667761c4591ab2da8e3f71fa0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c9aa0c7fa734470bfc3feed6592d3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6835ae446b484d3ca602ec2f617aaff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0dc4784cf42446fb83ce5e6f1162d21",
      "placeholder": "​",
      "style": "IPY_MODEL_04d91f88d2bd41c2911b27882b1bc3c4",
      "value": " 386k/? [00:00&lt;00:00, 11.6MB/s]"
     }
    },
    "9ddd39e4df4f422d894bd00d63808d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c9aa0c7fa734470bfc3feed6592d3bc",
      "placeholder": "​",
      "style": "IPY_MODEL_d29596beefdc42bea19fafd84f93dadb",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "
     }
    },
    "a0dc4784cf42446fb83ce5e6f1162d21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae273c49ff2a4099804ec2402c4e2d9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aee8df7ec2544bd89bdfbdb36a75191f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ddd39e4df4f422d894bd00d63808d90",
       "IPY_MODEL_b74d16cecf6e4c81b3ffd3df6be7845b",
       "IPY_MODEL_6835ae446b484d3ca602ec2f617aaff4"
      ],
      "layout": "IPY_MODEL_ae273c49ff2a4099804ec2402c4e2d9a"
     }
    },
    "b74d16cecf6e4c81b3ffd3df6be7845b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0489b43fc7e64734882843d7d1dbccce",
      "max": 47900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fb17667761c4591ab2da8e3f71fa0bd",
      "value": 47900
     }
    },
    "d29596beefdc42bea19fafd84f93dadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
