{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastasia-belkina/Master-Thesis/blob/main/Rule-Based%20Classifier/RB_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aa51dcb-9bd7-4adc-af2d-90655ed7b59d",
      "metadata": {
        "id": "6aa51dcb-9bd7-4adc-af2d-90655ed7b59d"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad73ef0b-5bb9-49b6-8491-81669a22974c",
      "metadata": {
        "id": "ad73ef0b-5bb9-49b6-8491-81669a22974c"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import stanza\n",
        "from afinn import Afinn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4b9a5d-f5f1-4b41-89b1-ef0f7ec9269b",
      "metadata": {
        "id": "5b4b9a5d-f5f1-4b41-89b1-ef0f7ec9269b"
      },
      "source": [
        "# Examples of NLTK libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b3c7715-37fc-438c-adcd-6e35a645887b",
      "metadata": {
        "id": "4b3c7715-37fc-438c-adcd-6e35a645887b"
      },
      "source": [
        "## Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634b2faf-13e3-44da-b6d4-46daf8b3d52a",
      "metadata": {
        "id": "634b2faf-13e3-44da-b6d4-46daf8b3d52a",
        "outputId": "fa46405e-0fdf-4760-b6d1-eb1698c067b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('incrimination.n.01'), Synset('blame.n.02'), Synset('blame.v.01'), Synset('blame.v.02'), Synset('blame.v.03'), Synset('blasted.s.01')]\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Example: Finding synonyms for a word\n",
        "synonyms = wordnet.synsets('blame')\n",
        "print(synonyms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44616a38-2c4e-4e33-8c9c-a8367fd76af0",
      "metadata": {
        "id": "44616a38-2c4e-4e33-8c9c-a8367fd76af0"
      },
      "source": [
        "## Tokenization and POS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8786510-44d7-4715-94e6-f2a0c3b9078e",
      "metadata": {
        "id": "c8786510-44d7-4715-94e6-f2a0c3b9078e",
        "outputId": "a96d064f-1c1a-46ba-a80e-7c6eaa8fc97c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'PRP'), ('is', 'VBZ'), ('responsible', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('failure', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "# Example: POS tagging a sentence\n",
        "sentence = \"He is responsible for the failure.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = pos_tag(tokens)\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8bdc200-36f4-4e01-9dee-abe66385ddbc",
      "metadata": {
        "id": "c8bdc200-36f4-4e01-9dee-abe66385ddbc"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679b42e0-84f6-4a57-81db-1d38d2466a6a",
      "metadata": {
        "id": "679b42e0-84f6-4a57-81db-1d38d2466a6a",
        "outputId": "b9d87d0c-28ab-41a2-925d-51766f4b0af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive: 0.0, Negative: 0.5, Objective: 0.5\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "# Example: Getting sentiment scores for a word\n",
        "word = list(swn.senti_synsets('blame'))[0]\n",
        "print(f\"Positive: {word.pos_score()}, Negative: {word.neg_score()}, Objective: {word.obj_score()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7790052-ef05-469d-847d-c138b8b8d913",
      "metadata": {
        "id": "f7790052-ef05-469d-847d-c138b8b8d913"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411920ea-b43c-467d-9d1a-05a30506fbb9",
      "metadata": {
        "id": "411920ea-b43c-467d-9d1a-05a30506fbb9",
        "outputId": "b025cad7-1f03-4807-a2a6-bdb1be5f3221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: ['This is a sentence.', 'Here is another one.']\n",
            "Words: ['This', 'is', 'a', 'sentence', '.', 'Here', 'is', 'another', 'one', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Example: Tokenizing a paragraph into sentences and words\n",
        "paragraph = \"This is a sentence. Here is another one.\"\n",
        "sentences = sent_tokenize(paragraph)\n",
        "words = word_tokenize(paragraph)\n",
        "\n",
        "print(\"Sentences:\", sentences)\n",
        "print(\"Words:\", words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8c2050-dce8-4e05-b0fa-0862bd1565f7",
      "metadata": {
        "id": "cc8c2050-dce8-4e05-b0fa-0862bd1565f7"
      },
      "source": [
        "## Open Lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1831d4b8-de0a-46ea-beb2-4d20b8277f14",
      "metadata": {
        "id": "1831d4b8-de0a-46ea-beb2-4d20b8277f14",
        "outputId": "662b2531-018e-452b-e81c-85977de7eb49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive words example: ['a+', 'abound', 'abounds', 'abundance', 'abundant']\n",
            "Negative words example: ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import opinion_lexicon\n",
        "\n",
        "# Example: Accessing positive and negative word lists\n",
        "positive_words = opinion_lexicon.positive()\n",
        "negative_words = opinion_lexicon.negative()\n",
        "\n",
        "print(\"Positive words example:\", positive_words[:5])\n",
        "print(\"Negative words example:\", negative_words[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "861c1c19-2c75-49ca-953f-971d5945dd14",
      "metadata": {
        "id": "861c1c19-2c75-49ca-953f-971d5945dd14"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0177e818-4652-4a7f-9b57-efca73673fd2",
      "metadata": {
        "id": "0177e818-4652-4a7f-9b57-efca73673fd2"
      },
      "source": [
        "How to Sequence These Steps\n",
        "The preprocessing pipeline generally follows this order:\n",
        "- Sentence Splitting and Tokenization\n",
        "- POS Tagging\n",
        "- Named Entity Recognition (NER)\n",
        "- Word Sense Disambiguation (WSD)\n",
        "- Dependency Parsing (including verb-object detection)\n",
        "- Polarity Detection (Sentiment Analysis) - SentiWordNet, AFINN and the Subjectivity Lexicon\n",
        "- Negation Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "462d8cb3-86c2-4118-bfd2-a9afa7f5d4a3",
      "metadata": {
        "id": "462d8cb3-86c2-4118-bfd2-a9afa7f5d4a3"
      },
      "source": [
        "## Sentence Splitting and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12c6c8a0-5c51-4670-8d12-cfae1237a141",
      "metadata": {
        "id": "12c6c8a0-5c51-4670-8d12-cfae1237a141"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb1fa4c-6660-4a4b-974e-f46b97aab888",
      "metadata": {
        "id": "3bb1fa4c-6660-4a4b-974e-f46b97aab888"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "29fda283-bf5a-474b-9658-c9cf037feef3",
      "metadata": {
        "id": "29fda283-bf5a-474b-9658-c9cf037feef3"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63991a14-4da8-4093-b98e-2b0d3bec9d93",
      "metadata": {
        "id": "63991a14-4da8-4093-b98e-2b0d3bec9d93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26089998-a0c6-4e62-84da-0e4f176a74b9",
      "metadata": {
        "id": "26089998-a0c6-4e62-84da-0e4f176a74b9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "93c3f0a9-987b-40c0-892c-115541a82056",
      "metadata": {
        "id": "93c3f0a9-987b-40c0-892c-115541a82056"
      },
      "source": [
        "## Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fba3c9-c4ec-4a96-8af2-7cc9c534747b",
      "metadata": {
        "id": "58fba3c9-c4ec-4a96-8af2-7cc9c534747b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe459da-2777-4aaf-83db-9a9143ab9d6f",
      "metadata": {
        "id": "0fe459da-2777-4aaf-83db-9a9143ab9d6f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "193d1fda-3b06-491a-9197-fcfed02c7432",
      "metadata": {
        "id": "193d1fda-3b06-491a-9197-fcfed02c7432"
      },
      "source": [
        "## Word Sense Disambiguation (WSD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5520b3-e184-4f7e-a5c9-11e550da51f4",
      "metadata": {
        "id": "4b5520b3-e184-4f7e-a5c9-11e550da51f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a130398d-efbc-4645-9c8a-94510feec0a1",
      "metadata": {
        "id": "a130398d-efbc-4645-9c8a-94510feec0a1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "db0c1923-27c4-4044-9266-96712fa73b06",
      "metadata": {
        "id": "db0c1923-27c4-4044-9266-96712fa73b06"
      },
      "source": [
        "## Dependency Parsing (including verb-object detection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0acc62c9-0ac2-4b36-b4ad-823d30eff69a",
      "metadata": {
        "id": "0acc62c9-0ac2-4b36-b4ad-823d30eff69a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2745bbd8-9487-41c2-a6cd-a2938c6dc7e9",
      "metadata": {
        "id": "2745bbd8-9487-41c2-a6cd-a2938c6dc7e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4bb37dc3-df8e-4d37-8046-205ad16d0196",
      "metadata": {
        "id": "4bb37dc3-df8e-4d37-8046-205ad16d0196"
      },
      "source": [
        "## Polarity Detection (Sentiment Analysis) - SentiWordNet, AFINN and the Subjectivity Lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf1cc7f-88c5-4b1f-aa5b-3df3237be9fc",
      "metadata": {
        "id": "0bf1cc7f-88c5-4b1f-aa5b-3df3237be9fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db16310-4313-4e8c-87ad-8803e1d518e3",
      "metadata": {
        "id": "1db16310-4313-4e8c-87ad-8803e1d518e3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "63116db7-e277-4418-8f93-ec9c8dca637b",
      "metadata": {
        "id": "63116db7-e277-4418-8f93-ec9c8dca637b"
      },
      "source": [
        "## Negation Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ac17a9-ab15-40f5-8aa7-18839e8a9592",
      "metadata": {
        "id": "26ac17a9-ab15-40f5-8aa7-18839e8a9592"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2629a6-24be-4e74-8464-2d6f24cde435",
      "metadata": {
        "id": "bc2629a6-24be-4e74-8464-2d6f24cde435"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c41a1a-c92a-4413-a397-db790b5e880a",
      "metadata": {
        "id": "b8c41a1a-c92a-4413-a397-db790b5e880a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}