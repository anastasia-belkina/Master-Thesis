{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee484548-0f4d-4182-a70f-aef0f0cd5b96",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d02f264-f222-4ffb-be3b-f0097f988b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import stanza\n",
    "import ast\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import verbnet as vn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b106f5-091e-4100-af31-f7677c66f1de",
   "metadata": {},
   "source": [
    "# Preprocessed Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1049d0-bd96-4662-988d-0db76fe1a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "column_names = [\"Sentence\", \"Label\", \"tokens_pos\", \"entities\", \"dependencies\"]\n",
    "df_train_ready = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/df_train_shuffled.txt', sep='\\t', names=column_names)\n",
    "df_valid_ready = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/df_valid_shuffled.txt', sep='\\t', names=column_names)\n",
    "\n",
    "# Remove leading and trailing spaces in the \"Sentence\" column\n",
    "df_train_ready['Sentence'] = df_train_ready['Sentence'].str.strip()\n",
    "df_valid_ready['Sentence'] = df_valid_ready['Sentence'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32502fac-70ca-4c2c-83be-a0f206d6b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a. m. Initial eyewitness accounts of such inci...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('a.', 'X'), ('m.', 'NOUN'), ('Initial', 'ADJ...</td>\n",
       "      <td>[('British', 'NORP'), ('Cox’s', 'PERSON')]</td>\n",
       "      <td>[('a.', 10, 'dep'), ('m.', 10, 'nsubj'), ('Ini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shortly after the beginning of the attack, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Shortly', 'ADV'), ('after', 'ADP'), ('the',...</td>\n",
       "      <td>[('Talibans', 'NORP'), ('Zabihullah Mujahid', ...</td>\n",
       "      <td>[('Shortly', 4, 'advmod'), ('after', 4, 'case'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Judge Pryor initially supported Judge Moore bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[('Judge', 'NOUN'), ('Pryor', 'PROPN'), ('init...</td>\n",
       "      <td>[('Pryor', 'PERSON'), ('Moore', 'PERSON')]</td>\n",
       "      <td>[('Judge', 4, 'nsubj'), ('Pryor', 1, 'flat'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump also expects to receive a major new fina...</td>\n",
       "      <td>3</td>\n",
       "      <td>[('Trump', 'PROPN'), ('also', 'ADV'), ('expect...</td>\n",
       "      <td>[('Trump', 'PERSON'), ('the United States', 'G...</td>\n",
       "      <td>[('Trump', 3, 'nsubj'), ('also', 3, 'advmod'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just decentralisation.Mr Purcell praised the C...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('just', 'ADV'), ('decentralisation', 'NOUN')...</td>\n",
       "      <td>[('Purcell', 'PERSON'), ('Coalition', 'ORG')]</td>\n",
       "      <td>[('just', 2, 'advmod'), ('decentralisation', 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label  \\\n",
       "0  a. m. Initial eyewitness accounts of such inci...      0   \n",
       "1  Shortly after the beginning of the attack, the...      1   \n",
       "2  Judge Pryor initially supported Judge Moore bu...      0   \n",
       "3  Trump also expects to receive a major new fina...      3   \n",
       "4  just decentralisation.Mr Purcell praised the C...      1   \n",
       "\n",
       "                                          tokens_pos  \\\n",
       "0  [('a.', 'X'), ('m.', 'NOUN'), ('Initial', 'ADJ...   \n",
       "1  [('Shortly', 'ADV'), ('after', 'ADP'), ('the',...   \n",
       "2  [('Judge', 'NOUN'), ('Pryor', 'PROPN'), ('init...   \n",
       "3  [('Trump', 'PROPN'), ('also', 'ADV'), ('expect...   \n",
       "4  [('just', 'ADV'), ('decentralisation', 'NOUN')...   \n",
       "\n",
       "                                            entities  \\\n",
       "0         [('British', 'NORP'), ('Cox’s', 'PERSON')]   \n",
       "1  [('Talibans', 'NORP'), ('Zabihullah Mujahid', ...   \n",
       "2         [('Pryor', 'PERSON'), ('Moore', 'PERSON')]   \n",
       "3  [('Trump', 'PERSON'), ('the United States', 'G...   \n",
       "4      [('Purcell', 'PERSON'), ('Coalition', 'ORG')]   \n",
       "\n",
       "                                        dependencies  \n",
       "0  [('a.', 10, 'dep'), ('m.', 10, 'nsubj'), ('Ini...  \n",
       "1  [('Shortly', 4, 'advmod'), ('after', 4, 'case'...  \n",
       "2  [('Judge', 4, 'nsubj'), ('Pryor', 1, 'flat'), ...  \n",
       "3  [('Trump', 3, 'nsubj'), ('also', 3, 'advmod'),...  \n",
       "4  [('just', 2, 'advmod'), ('decentralisation', 0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade7978-08a0-4c84-be4c-be6ed20f1d04",
   "metadata": {},
   "source": [
    "# Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aaba528-c606-4797-aeee-52437715a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary: 0 - neutral, 1 - positive, 2 - negative\n",
    "label_mapping = {2: 1, 3: 2, 4: 2}\n",
    "\n",
    "df_train_ready_merged = df_train_ready\n",
    "df_valid_ready_merged = df_valid_ready\n",
    "\n",
    "df_train_ready_merged['Label'] = df_train_ready_merged['Label'].replace(label_mapping)\n",
    "df_valid_ready_merged['Label'] = df_valid_ready_merged['Label'].replace(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a1cf9-5a57-493a-8c3a-7802f92ffba6",
   "metadata": {},
   "source": [
    "# Turning strings back to lists and tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e79989-3230-4c6b-ba9c-17d47543c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(dependencies_str):\n",
    "    # Check if it's a string and if it appears to be in the list of tuples format\n",
    "    if isinstance(dependencies_str, str) and dependencies_str.startswith(\"[\") and dependencies_str.endswith(\"]\"):\n",
    "        try:\n",
    "            # Convert string representation of list back to actual list of tuples\n",
    "            return ast.literal_eval(dependencies_str)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error parsing: {dependencies_str}\")\n",
    "            raise e\n",
    "    elif isinstance(dependencies_str, list):\n",
    "        # If it's already a list, return as is\n",
    "        return dependencies_str\n",
    "    else:\n",
    "        # If it's another unexpected type, return as is or handle appropriately\n",
    "        return dependencies_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e53857-0db5-4237-b8c7-e742c1fd955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to your datasets\n",
    "df_train_ready_merged['dependencies'] = df_train_ready_merged['dependencies'].apply(convert_to_list)\n",
    "df_valid_ready_merged['dependencies'] = df_valid_ready_merged['dependencies'].apply(convert_to_list)\n",
    "df_train_ready_merged['tokens_pos'] = df_train_ready_merged['tokens_pos'].apply(convert_to_list)\n",
    "df_valid_ready_merged['tokens_pos'] = df_valid_ready_merged['tokens_pos'].apply(convert_to_list)\n",
    "df_train_ready_merged['entities'] = df_train_ready_merged['entities'].apply(convert_to_list)\n",
    "df_valid_ready_merged['entities'] = df_valid_ready_merged['entities'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5898c-ac22-4229-9a87-3a89b6c3912e",
   "metadata": {},
   "source": [
    "# Following the Modified Algorithm of Blame/Praise Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850365df-dec0-4b8f-a92e-6631d0347707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to check if a verb belongs to Foreseeability or Coercion groups\n",
    "\n",
    "def is_foreseeability_verb(verb):\n",
    "    # This function checks whether a verb belongs to a predefined set of foreseeability-related verb classes.\n",
    "    foreseeability_classes = {'communication', 'creation', 'consumption', 'competition', 'possession', 'motion'}\n",
    "    synsets = wn.synsets(verb, pos=wn.VERB)  # Fetches all verb synsets for the word\n",
    "    for synset in synsets:\n",
    "        lexname = synset.lexname().split('.')[1]  # Extracts the lexical category (i.e., type of action)\n",
    "        if lexname in foreseeability_classes:  # Checks if the lexical category is in the foreseeability class\n",
    "            return True  # Returns True if the verb matches any foreseeability category\n",
    "    return False  # If no match is found, returns False\n",
    "\n",
    "\n",
    "def is_coercion_verb(verb):\n",
    "    # This function checks whether a verb belongs to a predefined set of coercion-related VerbNet classes.\n",
    "    coercion_classes = {'urge-58.1', 'force-59', 'forbid-67'}\n",
    "    synsets = wn.synsets(verb, pos=wn.VERB)  # Fetches all verb synsets for the word\n",
    "    for synset in synsets:\n",
    "        lemma = synset.lemmas()[0]  # Gets the first lemma for each synset\n",
    "        vn_classes = lemma.key().split('%')[0]  # Extracts the lemma key\n",
    "        vn_class_ids = vn.classids(vn_classes)  # Fetches the VerbNet classes for the lemma\n",
    "        if any(vn_class in coercion_classes for vn_class in vn_class_ids):  # Checks for a match in coercion classes\n",
    "            return True  # If a match is found in coercion classes, return True\n",
    "    return False  # If no match is found, return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c70245b-fa64-4e29-ae20-84f7f8999ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_verb(word, tokens_pos):\n",
    "    \"\"\"\n",
    "    Check if the given word is a verb and passes the foreseeability and coercion checks.\n",
    "    \"\"\"\n",
    "    # Check if the word is a verb using tokens_pos\n",
    "    for token, pos in tokens_pos:\n",
    "        if token == word and 'VERB' in pos:  # Ensure the word is tagged as a verb\n",
    "            # Now check if it passes foreseeability and coercion checks\n",
    "            if is_foreseeability_verb(word) and not is_coercion_verb(word):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_conjunctions(verb_type_verbs, related_word, counter_j, index, dependencies, tokens_pos):\n",
    "    \"\"\"\n",
    "    Helper function to check and append conjunctions for specific verb types (xcomp, ccomp, parataxis, advcl).\n",
    "    It modifies the original verb list (e.g., xcomp_verbs, ccomp_verbs) by adding conjunctions directly.\n",
    "    \"\"\"\n",
    "    counter_x = 0\n",
    "    for conj in dependencies:\n",
    "        if len(conj) == 3:\n",
    "            conj_word, conj_head, conj_rel = conj\n",
    "            counter_x += 1\n",
    "            # Reset counter for punctuation after root - end of the sentence\n",
    "            if conj_rel == 'punct' and (conj_word == \".\" or conj_word == \":\"):\n",
    "                counter_x = 0\n",
    "            # Check if the conj word is a valid verb related to the current relation\n",
    "            if conj_head == counter_j and conj_rel == 'conj' and is_valid_verb(related_word, tokens_pos):\n",
    "                verb_type_verbs.append((conj_word, counter_x, index))  # Append conjunction to the respective verb list\n",
    "\n",
    "\n",
    "def handle_related_verbs(related_rel, related_word, counter_j, index, dependencies, tokens_pos, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs):\n",
    "    \"\"\"\n",
    "    Helper function to handle related verbs (xcomp, ccomp, parataxis, advcl).\n",
    "    Depending on the relation type, it adds the verb to the appropriate list and handles its conjunctions.\n",
    "    \"\"\"\n",
    "    if related_rel == 'xcomp':\n",
    "        xcomp_verbs.append((related_word, counter_j, index))  # xcomp relation to root\n",
    "        check_conjunctions(xcomp_verbs, related_word, counter_j, index, dependencies, tokens_pos)\n",
    "\n",
    "    elif related_rel == 'ccomp':\n",
    "        ccomp_verbs.append((related_word, counter_j, index))  # ccomp relation\n",
    "        check_conjunctions(ccomp_verbs, related_word, counter_j, index, dependencies, tokens_pos)\n",
    "\n",
    "    elif related_rel == 'parataxis':\n",
    "        parataxis_verbs.append((related_word, counter_j, index))  # parataxis relation\n",
    "        check_conjunctions(parataxis_verbs, related_word, counter_j, index, dependencies, tokens_pos)\n",
    "\n",
    "    elif related_rel == 'advcl':\n",
    "        advcl_verbs.append((related_word, counter_j, index))  # advcl relation\n",
    "        check_conjunctions(advcl_verbs, related_word, counter_j, index, dependencies, tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ea980d-d800-4637-a05c-79f56cda0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_one_function(row):\n",
    "    \"\"\"\n",
    "    Main function to find valid verbs (root, xcomp, ccomp, parataxis, advcl, and their conjunctions).\n",
    "    \"\"\"\n",
    "    dependencies = row['dependencies']  # Dependency relations for the sentence\n",
    "    tokens_pos = row['tokens_pos']  # POS-tagged tokens for the sentence\n",
    "\n",
    "    counter_i = 0  # Counter for tracking the index of words in the dependency structure\n",
    "    \n",
    "    # Lists to store categorized verbs\n",
    "    roots = []  # (word, own index, main root), if root is root (not conj) - write its own index\n",
    "    root_verbs = []  # For valid root verbs (that pass foreseeability and coercion checks)\n",
    "    xcomp_verbs = []  # For valid xcomp verbs\n",
    "    ccomp_verbs = []  # For valid ccomp verbs\n",
    "    parataxis_verbs = []  # For valid parataxis verbs\n",
    "    advcl_verbs = []  # For valid advcl verbs\n",
    "\n",
    "    # Iterate through dependencies to identify roots and their related verbs\n",
    "    for dep in dependencies:\n",
    "        if len(dep) == 3:\n",
    "            word, head, deprel = dep  # Unpacking the dependency tuple (word, head, relation)\n",
    "            counter_i += 1  # Increment the index counter for this word\n",
    "\n",
    "            # Reset counter when punctuation is found after root\n",
    "            if roots:\n",
    "                if deprel == 'punct' and (word == \".\" or word == \":\") and head == roots[0][1]:\n",
    "                    counter_i = 0  \n",
    "\n",
    "            # Check if the current word is the root of the sentence\n",
    "            if deprel == 'root':\n",
    "                roots.append((word, counter_i, counter_i))  # Add the root verb and its index\n",
    "                if is_valid_verb(word, tokens_pos):  # Check if the root is a valid verb\n",
    "                    root_verbs.append((word, counter_i, counter_i))  # Append valid root verb\n",
    "\n",
    "                # Looking for related conjunctions\n",
    "                counter_j = 0\n",
    "                for related in dependencies:\n",
    "                    if len(related) == 3:\n",
    "                        related_word, related_head, related_rel = related\n",
    "                        counter_j += 1  # Increment index for related word\n",
    "                        # Reset the counter for punctuation after root\n",
    "                        if related_rel == 'punct' and (related_word == \".\" or related_word == \":\") and related_head == roots[0][1]:\n",
    "                            counter_j = 0\n",
    "                        # Look for conjunctions attached to the root verb\n",
    "                        if related_head == counter_i and related_rel == 'conj' and is_valid_verb(related_word, tokens_pos):\n",
    "                            roots.append((related_word, counter_j, counter_i))  # Add root conj\n",
    "                            root_verbs.append((related_word, counter_j, counter_i))  # Append valid conj relation\n",
    "\n",
    "    # Find related verbs (xcomp, ccomp, etc.) for root verbs and their conjunctions\n",
    "    for verb in roots:\n",
    "        word, index, head_index = verb\n",
    "        counter_j = 0\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                counter_j += 1\n",
    "                # Reset the counter for punctuation after root\n",
    "                if related_rel == 'punct' and (related_word == \".\" or related_word == \":\") and related_head == roots[0][1]:\n",
    "                    counter_j = 0\n",
    "                # Handle xcomp, ccomp, parataxis, and advcl relations\n",
    "                if related_head == index and related_rel in ['xcomp', 'ccomp', 'parataxis', 'advcl'] and is_valid_verb(related_word, tokens_pos):\n",
    "                    handle_related_verbs(related_rel, related_word, counter_j, index, dependencies, tokens_pos, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs)\n",
    "\n",
    "    return roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30dbe389-4669-4a18-9135-f9128335f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_agent_validity(related_word, row, tokens_pos):\n",
    "    \"\"\"\n",
    "    Function to check the validity of an agent based on NER tags and additional rules.\n",
    "    \"\"\"\n",
    "    entities = row['entities']\n",
    "    valid_ent_labels = [\"PERSON\", \"NORP\", \"ORG\", \"GPE\"]\n",
    "    valid_additional_words = [\n",
    "        \"person\", \"man\", \"woman\", \"police\", \"administration\", \"immigrants\", \"president\", \"minister\", \"senator\", \n",
    "        \"representative\", \"governor\", \"mayor\", \"council\", \"secretary\", \"ambassador\", \"chancellor\", \n",
    "        \"parliamentary\", \"mr.\", \"ms.\", \"mrs.\"\n",
    "    ]\n",
    "\n",
    "    self = False\n",
    "    agent_is_valid = False\n",
    "    \n",
    "    # Original logic: Check if the related_word is a valid agent based on NER and additional terms\n",
    "    for entity, label in entities: \n",
    "        if related_word in entity and label in valid_ent_labels:  \n",
    "            agent_is_valid = True  # Valid agent based on NER\n",
    "    \n",
    "    # Check if it's a pronoun\n",
    "    if not agent_is_valid and 'PRON' in [pos for token, pos in tokens_pos if token == related_word]: \n",
    "        agent_is_valid = True  \n",
    "        # Logic for handling \"self\" reference (i.e., \"I\" or \"we\") - to be changed\n",
    "        #if related_word.lower() == \"i\" or related_word.lower() == \"we\":\n",
    "            #self = True\n",
    "\n",
    "    # Check if the word is in additional valid agent words\n",
    "    if not agent_is_valid and related_word.lower() in valid_additional_words:\n",
    "        agent_is_valid = True  \n",
    "\n",
    "    return agent_is_valid, self\n",
    "\n",
    "\n",
    "def check_causative_verb(verb):\n",
    "    \"\"\"\n",
    "    Function to check if the verb is causative, i.e., if it belongs to the 'cause' or 'CAUSETO' class.\n",
    "    \"\"\"\n",
    "    for synset in wn.synsets(verb, pos=wn.VERB):\n",
    "        if 'cause' in synset.lemma_names():\n",
    "            return True\n",
    "        for lemma in synset.lemmas():\n",
    "            for frame in lemma.frame_strings():\n",
    "                if 'CAUSE' in frame or 'CAUSETO' in frame:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def define_polarity(verb, obj):\n",
    "    \"\"\"\n",
    "    Function to define the polarity of the verb + object combination.\n",
    "    Uses Word Sense Disambiguation (WSD) and several sentiment analysis tools.\n",
    "    \"\"\"\n",
    "    context = f\"{verb} {obj}\"\n",
    "    verb_sense = lesk(context.split(), verb, 'v')\n",
    "    obj_sense = lesk(context.split(), obj, 'n')\n",
    "    \n",
    "    pos_score = neg_score = 0\n",
    "    \n",
    "    if verb_sense:\n",
    "        swn_verb = swn.senti_synset(verb_sense.name())\n",
    "        pos_score += swn_verb.pos_score()\n",
    "        neg_score += swn_verb.neg_score()\n",
    "    \n",
    "    if obj_sense:\n",
    "        swn_obj = swn.senti_synset(obj_sense.name())\n",
    "        pos_score += swn_obj.pos_score()\n",
    "        neg_score += swn_obj.neg_score()\n",
    "\n",
    "    afinn_score = afinn.score(context)\n",
    "    if afinn_score > 0:\n",
    "        pos_score += afinn_score\n",
    "    else:\n",
    "        neg_score += abs(afinn_score)\n",
    "\n",
    "    subj_pos = sum([1 for token in context.split() if token in opinion_lexicon.positive()])\n",
    "    subj_neg = sum([1 for token in context.split() if token in opinion_lexicon.negative()])\n",
    "    \n",
    "    pos_score += subj_pos\n",
    "    neg_score += subj_neg\n",
    "\n",
    "    return 1 if pos_score > neg_score else 2 if neg_score > pos_score else 0\n",
    "\n",
    "\n",
    "def adjust_sentiment_for_negation(row, polarity, verb):\n",
    "    \"\"\"\n",
    "    Function to adjust the sentiment polarity for negation.\n",
    "    \"\"\"\n",
    "    word, index, head_index = verb\n",
    "    dependencies = row['dependencies']\n",
    "\n",
    "    for related in dependencies:\n",
    "        if len(related) == 3:\n",
    "            related_word, related_head, related_rel = related\n",
    "            if related_head == index and related_rel in ['advmod'] and (related_word == 'not' or related_word == 'n’t'):\n",
    "                return 2 if polarity == 1 else 1 if polarity == 2 else 0\n",
    "    \n",
    "    return polarity\n",
    "\n",
    "\n",
    "\n",
    "def handle_special_cases_for_xcomp_in_ccomp(row, verb, dependencies, tokens_pos, counter_j, related_word):\n",
    "    \"\"\"\n",
    "    Handle special cases for xcomp connected to ccomp, looking for objects connected to xcomp.\n",
    "    \"\"\"\n",
    "    for related_to_xcomp in dependencies:\n",
    "        if len(related_to_xcomp) == 3:\n",
    "            related_to_xcomp_word, related_to_xcomp_head, related_to_xcomp_rel = related_to_xcomp\n",
    "            if related_to_xcomp_head == counter_j and related_to_xcomp_rel in ['obj', 'iobj', 'obl']:\n",
    "                # Define polarity of the combination xcomp + object\n",
    "                polarity = define_polarity(related_word, related_to_xcomp_word)\n",
    "                polarity = adjust_sentiment_for_negation(row, polarity, related_to_xcomp)\n",
    "                if polarity != 0:\n",
    "                    return polarity\n",
    "    return 0\n",
    "\n",
    "\n",
    "def process_ccomp_verb(row, verb, dependencies, tokens_pos, roots):\n",
    "    \"\"\"\n",
    "    Process ccomp verbs and handle normal cases and special cases like `obl:agent` and `nsubj:pass`.\n",
    "    \"\"\"\n",
    "    word, index, head_index = verb\n",
    "    agent_is_valid, self = False, False\n",
    "    agent_is_obl = False  # Track if the agent comes from an `obl:agent`\n",
    "\n",
    "    # Find an agent connected to the ccomp verb (normal or obl:agent case)\n",
    "    for related in dependencies:\n",
    "        if len(related) == 3:\n",
    "            related_word, related_head, related_rel = related\n",
    "            # Check for `nsubj` as agent\n",
    "            if related_head == index and related_rel in ['nsubj']:\n",
    "                agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "\n",
    "            # Special case: `obl:agent` becomes the agent\n",
    "            elif related_head == index and related_rel in ['obl:agent', 'obl']:\n",
    "                agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "                agent_is_obl = True  # Mark that the agent is an `obl`\n",
    "\n",
    "    # If no valid agent, check for causative verbs\n",
    "    if not agent_is_valid and check_causative_verb(word):\n",
    "        agent_is_valid = True\n",
    "\n",
    "    # Object processing priority: `obj`, `iobj`\n",
    "    if agent_is_valid:\n",
    "        counter_j = 0\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                counter_j += 1\n",
    "                # Reset counter for punctuation\n",
    "                if related_rel == 'punct' and (related_word == \".\" or related_word == \":\") and related_head == roots[0][1]:\n",
    "                    counter_j = 0\n",
    "                \n",
    "                # Normal case: Handle objects connected to the ccomp verb\n",
    "                if related_head == index and related_rel in ['obj', 'iobj'] and not agent_is_obl:\n",
    "                    polarity = define_polarity(word, related_word)\n",
    "                    polarity = adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    if polarity != 0:\n",
    "                        return f\"self - {polarity}\" if self else polarity\n",
    "\n",
    "                # Special case: When `obl:agent` is present, `nsubj:pass` becomes the object\n",
    "                if agent_is_obl and related_head == index and related_rel == 'nsubj:pass':\n",
    "                    polarity = define_polarity(word, related_word)\n",
    "                    polarity = adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                    if polarity != 0:\n",
    "                        return f\"self - {polarity}\" if self else polarity\n",
    "\n",
    "                # Handle xcomp connected to ccomp and check objects within xcomp\n",
    "                polarity = handle_special_cases_for_xcomp_in_ccomp(row, verb, dependencies, tokens_pos, counter_j, related_word)\n",
    "                if polarity != 0:\n",
    "                    return f\"self - {polarity}\" if self else polarity\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def find_object_and_define_polarity(row, verb, agent_is_valid, tokens_pos):\n",
    "    \"\"\"\n",
    "    Helper function to find the object for a given verb and define its polarity.\n",
    "    \"\"\"\n",
    "    if agent_is_valid:\n",
    "        dependencies = row['dependencies']\n",
    "        for related in dependencies:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                # Maintain order of processing 'obj', 'iobj', and 'obl'\n",
    "                if related_head == verb[1] and related_rel in ['obj']:\n",
    "                    polarity = define_polarity(verb[0], related_word)\n",
    "                    return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "                \n",
    "                if related_head == verb[1] and related_rel in ['iobj']:\n",
    "                    polarity = define_polarity(verb[0], related_word)\n",
    "                    return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "\n",
    "                if related_head == verb[1] and related_rel in ['obl']:\n",
    "                    polarity = define_polarity(verb[0], related_word)\n",
    "                    return adjust_sentiment_for_negation(row, polarity, verb)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def process_verb_connections(row, verbs, tokens_pos, self=False):\n",
    "    \"\"\"\n",
    "    Generalized function to process verb connections such as root_verbs, xcomp_verbs, etc.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    for verb in verbs:\n",
    "        word, index, head_index = verb\n",
    "        agent_is_valid = False\n",
    "\n",
    "        # Original logic for agent validation\n",
    "        for related in row['dependencies']:\n",
    "            if len(related) == 3:\n",
    "                related_word, related_head, related_rel = related\n",
    "                if related_head == index and related_rel in ['nsubj', 'nsubj:pass']:\n",
    "                    agent_is_valid, self = check_agent_validity(related_word, row, tokens_pos)\n",
    "\n",
    "        # If agent is not valid, check causative verb\n",
    "        if not agent_is_valid and check_causative_verb(word):\n",
    "            agent_is_valid = True\n",
    "\n",
    "        # Use original priority order for object detection\n",
    "        polarity = find_object_and_define_polarity(row, verb, agent_is_valid, tokens_pos)\n",
    "        if polarity != 0:\n",
    "            return f\"self - {polarity}\" if self else polarity\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01c3852-ef74-496c-aeb5-95f01c929ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_two_function(row, roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs):\n",
    "    \"\"\"\n",
    "    Main function to decide on Agent Causality, find the object, decide on Polarity, and classify the row.\n",
    "    \"\"\"\n",
    "    tokens_pos = row['tokens_pos']\n",
    "    dependencies = row['dependencies']\n",
    "\n",
    "    # Process root verbs\n",
    "    result = process_verb_connections(row, root_verbs, tokens_pos)\n",
    "    if result:\n",
    "        return result\n",
    "\n",
    "    # Process ccomp verbs with priority handling and special cases\n",
    "    for verb in ccomp_verbs:\n",
    "        result = process_ccomp_verb(row, verb, dependencies, tokens_pos, roots)\n",
    "        if result:\n",
    "            return result\n",
    "\n",
    "    # Process advcl verbs\n",
    "    result = process_verb_connections(row, advcl_verbs, tokens_pos)\n",
    "    if result:\n",
    "        return result\n",
    "        \n",
    "    # Process parataxis verbs\n",
    "    result = process_verb_connections(row, parataxis_verbs, tokens_pos)\n",
    "    if result:\n",
    "        return result\n",
    "    \n",
    "    # Process xcomp verbs\n",
    "    result = process_verb_connections(row, xcomp_verbs, tokens_pos)\n",
    "    if result:\n",
    "        return result\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e4e0cf-d699-42a2-968b-063783d3a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_the_row(row):\n",
    "    \n",
    "    # This is the main function to process each row of data and classify the row \n",
    "\n",
    "    # 1 - Find all the related verbs in categories in dependency column 'root', 'xcomp', 'ccomp', 'parataxis', 'advcl', 'conj' (is a verb check - foreseeability check - coercion check)\n",
    "    roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs = step_one_function(row)\n",
    "    \n",
    "    # 2 - If at least one of the lists is not empty - can proceed\n",
    "    if root_verbs or xcomp_verbs or ccomp_verbs or parataxis_verbs or advcl_verbs:\n",
    "        \n",
    "        # 3 - Take a final decision about the label (0 - others, 1 - positive, 2 - negative)\n",
    "        return step_two_function(row, roots, root_verbs, xcomp_verbs, ccomp_verbs, parataxis_verbs, advcl_verbs)\n",
    "    \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33375c99-60a7-4f95-a5d1-87d16c49c0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the function to the dataset\n",
    "df_train_ready_merged['Final_Result'] = df_train_ready_merged.apply(label_the_row, axis=1)\n",
    "df_train_ready_merged = df_train_ready_merged[['Sentence', 'Label', 'Final_Result'] + [col for col in df_train_ready_merged.columns if col not in ['Sentence', 'Label', 'Final_Result']]]\n",
    "df_valid_ready_merged['Final_Result'] = df_valid_ready_merged.apply(label_the_row, axis=1)\n",
    "df_valid_ready_merged = df_valid_ready_merged[['Sentence', 'Label', 'Final_Result'] + [col for col in df_valid_ready_merged.columns if col not in ['Sentence', 'Label', 'Final_Result']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915deb00-52fe-4572-b9e7-5a7f68e35cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Result\n",
       "0    3590\n",
       "2     798\n",
       "1     644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ready_merged['Final_Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d1c91f-3ad7-4025-a5fe-671a593c81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final_Result\n",
       "0    409\n",
       "2     86\n",
       "1     55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_ready_merged['Final_Result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80232b5-0c37-466e-9c42-8022250cea6e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427d92c-2bc0-43d1-9e4a-e7ac7590985c",
   "metadata": {},
   "source": [
    "## Map values in Final_Result column to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d74c33e-c339-4f34-9040-a776c93b3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary: 0 - neutral, 1 - praise, 2 - blame\n",
    "label_mapping = {\"self - 1\": 1, \"self - 2\": 2}\n",
    "\n",
    "df_train_ready_merged['Final_Result'] = df_train_ready_merged['Final_Result'].replace(label_mapping)\n",
    "df_valid_ready_merged['Final_Result'] = df_valid_ready_merged['Final_Result'].replace(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee14185-795a-4684-92e8-06358fb39bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_eval = df_train_ready_merged[['Sentence', 'Label', 'Final_Result']]\n",
    "df_valid_eval = df_valid_ready_merged[['Sentence', 'Label', 'Final_Result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e40a5-4319-4f03-921d-cd7c3953eb84",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81a296a3-fa30-49fa-a7f1-701772bc3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels and predicted labels\n",
    "y_true_train = df_train_eval['Label']\n",
    "y_pred_train = df_train_eval['Final_Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b674ec-f8c7-4c94-a771-73660a1670f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric  Micro-average  Macro-average  Weighted-average\n",
      "0   F1 Score       0.579491       0.481979          0.554016\n",
      "1  Precision       0.579491       0.527924               NaN\n",
      "2     Recall       0.579491       0.475457               NaN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.70      2733\n",
      "           1       0.38      0.31      0.34       798\n",
      "           2       0.59      0.31      0.41      1501\n",
      "\n",
      "    accuracy                           0.58      5032\n",
      "   macro avg       0.53      0.48      0.48      5032\n",
      "weighted avg       0.57      0.58      0.55      5032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame with 'Label' as true labels and 'Final_Result' as predicted labels\n",
    "\n",
    "# Calculate F1 Scores\n",
    "f1_micro = f1_score(y_true_train, y_pred_train, average='micro')\n",
    "f1_macro = f1_score(y_true_train, y_pred_train, average='macro')\n",
    "f1_weighted = f1_score(y_true_train, y_pred_train, average='weighted')\n",
    "\n",
    "# Calculate Precision and Recall for completeness (optional)\n",
    "precision_micro = precision_score(y_true_train, y_pred_train, average='micro')\n",
    "precision_macro = precision_score(y_true_train, y_pred_train, average='macro')\n",
    "recall_micro = recall_score(y_true_train, y_pred_train, average='micro')\n",
    "recall_macro = recall_score(y_true_train, y_pred_train, average='macro')\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['F1 Score', 'Precision', 'Recall'],\n",
    "    'Micro-average': [f1_micro, precision_micro, recall_micro],\n",
    "    'Macro-average': [f1_macro, precision_macro, recall_macro],\n",
    "    'Weighted-average': [f1_weighted, None, None]  # Weighted average only applicable to F1 score here\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(results_df)\n",
    "\n",
    "# You can also use classification report to see more detailed metrics\n",
    "print(classification_report(y_true_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46642122-b89b-49fc-9463-56e7b5c447c8",
   "metadata": {},
   "source": [
    "### valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8fa5b22-60a0-4dcb-b334-223b84179568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels and predicted labels\n",
    "y_true_valid = df_valid_eval['Label']\n",
    "y_pred_valid = df_valid_eval['Final_Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dfaea35-0810-4955-870e-75195f16a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric  Micro-average  Macro-average  Weighted-average\n",
      "0   F1 Score            0.6       0.507397          0.571171\n",
      "1  Precision            0.6       0.568874               NaN\n",
      "2     Recall            0.6       0.494868               NaN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       305\n",
      "           1       0.51      0.36      0.42        78\n",
      "           2       0.58      0.30      0.40       167\n",
      "\n",
      "    accuracy                           0.60       550\n",
      "   macro avg       0.57      0.49      0.51       550\n",
      "weighted avg       0.59      0.60      0.57       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame with 'Label' as true labels and 'Final_Result' as predicted labels\n",
    "\n",
    "# Calculate F1 Scores\n",
    "f1_micro = f1_score(y_true_valid, y_pred_valid, average='micro')\n",
    "f1_macro = f1_score(y_true_valid, y_pred_valid, average='macro')\n",
    "f1_weighted = f1_score(y_true_valid, y_pred_valid, average='weighted')\n",
    "\n",
    "# Calculate Precision and Recall for completeness (optional)\n",
    "precision_micro = precision_score(y_true_valid, y_pred_valid, average='micro')\n",
    "precision_macro = precision_score(y_true_valid, y_pred_valid, average='macro')\n",
    "recall_micro = recall_score(y_true_valid, y_pred_valid, average='micro')\n",
    "recall_macro = recall_score(y_true_valid, y_pred_valid, average='macro')\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['F1 Score', 'Precision', 'Recall'],\n",
    "    'Micro-average': [f1_micro, precision_micro, recall_micro],\n",
    "    'Macro-average': [f1_macro, precision_macro, recall_macro],\n",
    "    'Weighted-average': [f1_weighted, None, None]  # Weighted average only applicable to F1 score here\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(results_df)\n",
    "\n",
    "# You can also use classification report to see more detailed metrics\n",
    "print(classification_report(y_true_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535b422-aeb1-4329-9a84-806b2983166c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6aa51dcb-9bd7-4adc-af2d-90655ed7b59d",
    "5b4b9a5d-f5f1-4b41-89b1-ef0f7ec9269b",
    "XgpcdWkBTA2i"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0489b43fc7e64734882843d7d1dbccce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d91f88d2bd41c2911b27882b1bc3c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fb17667761c4591ab2da8e3f71fa0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c9aa0c7fa734470bfc3feed6592d3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6835ae446b484d3ca602ec2f617aaff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0dc4784cf42446fb83ce5e6f1162d21",
      "placeholder": "​",
      "style": "IPY_MODEL_04d91f88d2bd41c2911b27882b1bc3c4",
      "value": " 386k/? [00:00&lt;00:00, 11.6MB/s]"
     }
    },
    "9ddd39e4df4f422d894bd00d63808d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c9aa0c7fa734470bfc3feed6592d3bc",
      "placeholder": "​",
      "style": "IPY_MODEL_d29596beefdc42bea19fafd84f93dadb",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "
     }
    },
    "a0dc4784cf42446fb83ce5e6f1162d21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae273c49ff2a4099804ec2402c4e2d9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aee8df7ec2544bd89bdfbdb36a75191f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ddd39e4df4f422d894bd00d63808d90",
       "IPY_MODEL_b74d16cecf6e4c81b3ffd3df6be7845b",
       "IPY_MODEL_6835ae446b484d3ca602ec2f617aaff4"
      ],
      "layout": "IPY_MODEL_ae273c49ff2a4099804ec2402c4e2d9a"
     }
    },
    "b74d16cecf6e4c81b3ffd3df6be7845b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0489b43fc7e64734882843d7d1dbccce",
      "max": 47900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fb17667761c4591ab2da8e3f71fa0bd",
      "value": 47900
     }
    },
    "d29596beefdc42bea19fafd84f93dadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
