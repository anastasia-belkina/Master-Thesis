{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee484548-0f4d-4182-a70f-aef0f0cd5b96",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d02f264-f222-4ffb-be3b-f0097f988b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import stanza\n",
    "import ast\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import verbnet as vn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b106f5-091e-4100-af31-f7677c66f1de",
   "metadata": {},
   "source": [
    "# Preprocessed Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1049d0-bd96-4662-988d-0db76fe1a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "#column_names = [\"Sentence\", \"Label\", \"tokens_pos\", \"entities\", \"dependencies\"]\n",
    "#shuffled_df = pd.read_csv('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/datasets_preprocessed/shuffled_df.txt', sep='\\t', names=column_names)\n",
    "\n",
    "# Load from Excel file\n",
    "column_names = [\"Sentence\", \"Label\", \"Their_Label\", \"tokens_pos\", \"entities\", \"dependencies\"]\n",
    "shuffled_df = pd.read_excel('C:/Users/Anastasiia Belkina/MANNHEIM/MASTER_THESIS_CODE/Rule-Based Classifier/shuffled_1_df_4th_model_100_rows.xlsx', sheet_name=\"Clean\", names=column_names)\n",
    "\n",
    "# Remove leading and trailing spaces in the \"Sentence\" column\n",
    "shuffled_df['Sentence'] = shuffled_df['Sentence'].str.strip()\n",
    "\n",
    "# First 100 rows for examples\n",
    "#shuffled_df = shuffled_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32502fac-70ca-4c2c-83be-a0f206d6b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Their_Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2011, of State Hillary Clinton promised the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('In', 'ADP'), ('2011', 'NUM'), (',', 'PUNCT'...</td>\n",
       "      <td>[('2011', 'DATE'), ('State', 'ORG'), ('Hillary...</td>\n",
       "      <td>[('In', 2, 'case'), ('2011', 8, 'obl'), (',', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>’ Today saw the debut of ”,” a new social expe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('’', 'PUNCT'), ('Today', 'NOUN'), ('saw', 'V...</td>\n",
       "      <td>[('Twitch', 'PRODUCT')]</td>\n",
       "      <td>[('’', 3, 'punct'), ('Today', 3, 'nsubj'), ('s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer, actor and activist Harry Belafonte, 88...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Singer', 'NOUN'), (',', 'PUNCT'), ('actor',...</td>\n",
       "      <td>[('Harry Belafonte', 'PERSON'), ('88', 'DATE')...</td>\n",
       "      <td>[('Singer', 12, 'nsubj'), (',', 3, 'punct'), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, Roberts said the teams medical staf...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Last', 'ADJ'), ('week', 'NOUN'), (',', 'PUN...</td>\n",
       "      <td>[('Last week', 'DATE'), ('Roberts', 'PERSON'),...</td>\n",
       "      <td>[('Last', 2, 'amod'), ('week', 5, 'obl:tmod'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indeed, I believe that Waitrose does more than...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Indeed', 'ADV'), (',', 'PUNCT'), ('I', 'PRO...</td>\n",
       "      <td>[('Waitrose', 'ORG'), ('UK', 'GPE')]</td>\n",
       "      <td>[('Indeed', 4, 'advmod'), (',', 4, 'punct'), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label  Their_Label  \\\n",
       "0  In 2011, of State Hillary Clinton promised the...      0            0   \n",
       "1  ’ Today saw the debut of ”,” a new social expe...      0            0   \n",
       "2  Singer, actor and activist Harry Belafonte, 88...      1            1   \n",
       "3  Last week, Roberts said the teams medical staf...      0            1   \n",
       "4  Indeed, I believe that Waitrose does more than...      0            1   \n",
       "\n",
       "                                          tokens_pos  \\\n",
       "0  [('In', 'ADP'), ('2011', 'NUM'), (',', 'PUNCT'...   \n",
       "1  [('’', 'PUNCT'), ('Today', 'NOUN'), ('saw', 'V...   \n",
       "2  [('Singer', 'NOUN'), (',', 'PUNCT'), ('actor',...   \n",
       "3  [('Last', 'ADJ'), ('week', 'NOUN'), (',', 'PUN...   \n",
       "4  [('Indeed', 'ADV'), (',', 'PUNCT'), ('I', 'PRO...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [('2011', 'DATE'), ('State', 'ORG'), ('Hillary...   \n",
       "1                            [('Twitch', 'PRODUCT')]   \n",
       "2  [('Harry Belafonte', 'PERSON'), ('88', 'DATE')...   \n",
       "3  [('Last week', 'DATE'), ('Roberts', 'PERSON'),...   \n",
       "4               [('Waitrose', 'ORG'), ('UK', 'GPE')]   \n",
       "\n",
       "                                        dependencies  \n",
       "0  [('In', 2, 'case'), ('2011', 8, 'obl'), (',', ...  \n",
       "1  [('’', 3, 'punct'), ('Today', 3, 'nsubj'), ('s...  \n",
       "2  [('Singer', 12, 'nsubj'), (',', 3, 'punct'), (...  \n",
       "3  [('Last', 2, 'amod'), ('week', 5, 'obl:tmod'),...  \n",
       "4  [('Indeed', 4, 'advmod'), (',', 4, 'punct'), (...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab333b5-5052-4dc7-aa98-b229e3cd04e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6c6add-31b2-4365-82c7-983097d03a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    71\n",
       "2    21\n",
       "1     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade7978-08a0-4c84-be4c-be6ed20f1d04",
   "metadata": {},
   "source": [
    "# Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aaba528-c606-4797-aeee-52437715a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary: 0 - neutral, 1 - positive, 2 - negative\n",
    "label_mapping = {2: 1, 3: 2, 4: 2}\n",
    "shuffled_df['Label'] = shuffled_df['Label'].replace(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ce2526-47fa-4485-8d66-1e9810305f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Their_Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2011, of State Hillary Clinton promised the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('In', 'ADP'), ('2011', 'NUM'), (',', 'PUNCT'...</td>\n",
       "      <td>[('2011', 'DATE'), ('State', 'ORG'), ('Hillary...</td>\n",
       "      <td>[('In', 2, 'case'), ('2011', 8, 'obl'), (',', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>’ Today saw the debut of ”,” a new social expe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('’', 'PUNCT'), ('Today', 'NOUN'), ('saw', 'V...</td>\n",
       "      <td>[('Twitch', 'PRODUCT')]</td>\n",
       "      <td>[('’', 3, 'punct'), ('Today', 3, 'nsubj'), ('s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer, actor and activist Harry Belafonte, 88...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Singer', 'NOUN'), (',', 'PUNCT'), ('actor',...</td>\n",
       "      <td>[('Harry Belafonte', 'PERSON'), ('88', 'DATE')...</td>\n",
       "      <td>[('Singer', 12, 'nsubj'), (',', 3, 'punct'), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, Roberts said the teams medical staf...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Last', 'ADJ'), ('week', 'NOUN'), (',', 'PUN...</td>\n",
       "      <td>[('Last week', 'DATE'), ('Roberts', 'PERSON'),...</td>\n",
       "      <td>[('Last', 2, 'amod'), ('week', 5, 'obl:tmod'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indeed, I believe that Waitrose does more than...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Indeed', 'ADV'), (',', 'PUNCT'), ('I', 'PRO...</td>\n",
       "      <td>[('Waitrose', 'ORG'), ('UK', 'GPE')]</td>\n",
       "      <td>[('Indeed', 4, 'advmod'), (',', 4, 'punct'), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label  Their_Label  \\\n",
       "0  In 2011, of State Hillary Clinton promised the...      0            0   \n",
       "1  ’ Today saw the debut of ”,” a new social expe...      0            0   \n",
       "2  Singer, actor and activist Harry Belafonte, 88...      1            1   \n",
       "3  Last week, Roberts said the teams medical staf...      0            1   \n",
       "4  Indeed, I believe that Waitrose does more than...      0            1   \n",
       "\n",
       "                                          tokens_pos  \\\n",
       "0  [('In', 'ADP'), ('2011', 'NUM'), (',', 'PUNCT'...   \n",
       "1  [('’', 'PUNCT'), ('Today', 'NOUN'), ('saw', 'V...   \n",
       "2  [('Singer', 'NOUN'), (',', 'PUNCT'), ('actor',...   \n",
       "3  [('Last', 'ADJ'), ('week', 'NOUN'), (',', 'PUN...   \n",
       "4  [('Indeed', 'ADV'), (',', 'PUNCT'), ('I', 'PRO...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [('2011', 'DATE'), ('State', 'ORG'), ('Hillary...   \n",
       "1                            [('Twitch', 'PRODUCT')]   \n",
       "2  [('Harry Belafonte', 'PERSON'), ('88', 'DATE')...   \n",
       "3  [('Last week', 'DATE'), ('Roberts', 'PERSON'),...   \n",
       "4               [('Waitrose', 'ORG'), ('UK', 'GPE')]   \n",
       "\n",
       "                                        dependencies  \n",
       "0  [('In', 2, 'case'), ('2011', 8, 'obl'), (',', ...  \n",
       "1  [('’', 3, 'punct'), ('Today', 3, 'nsubj'), ('s...  \n",
       "2  [('Singer', 12, 'nsubj'), (',', 3, 'punct'), (...  \n",
       "3  [('Last', 2, 'amod'), ('week', 5, 'obl:tmod'),...  \n",
       "4  [('Indeed', 4, 'advmod'), (',', 4, 'punct'), (...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af8d5ed-9357-4ded-970e-eed179b2ebef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e5a722-13c5-4d28-9e66-6713f70950f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    71\n",
       "1    29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a1cf9-5a57-493a-8c3a-7802f92ffba6",
   "metadata": {},
   "source": [
    "# Turning strings back to lists and tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e79989-3230-4c6b-ba9c-17d47543c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(dependencies_str):\n",
    "    # Check if it's a string and if it appears to be in the list of tuples format\n",
    "    if isinstance(dependencies_str, str) and dependencies_str.startswith(\"[\") and dependencies_str.endswith(\"]\"):\n",
    "        try:\n",
    "            # Convert string representation of list back to actual list of tuples\n",
    "            return ast.literal_eval(dependencies_str)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error parsing: {dependencies_str}\")\n",
    "            raise e\n",
    "    elif isinstance(dependencies_str, list):\n",
    "        # If it's already a list, return as is\n",
    "        return dependencies_str\n",
    "    else:\n",
    "        # If it's another unexpected type, return as is or handle appropriately\n",
    "        return dependencies_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e53857-0db5-4237-b8c7-e742c1fd955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to your datasets\n",
    "shuffled_df['dependencies'] = shuffled_df['dependencies'].apply(convert_to_list)\n",
    "shuffled_df['tokens_pos'] = shuffled_df['tokens_pos'].apply(convert_to_list)\n",
    "shuffled_df['entities'] = shuffled_df['entities'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5898c-ac22-4229-9a87-3a89b6c3912e",
   "metadata": {},
   "source": [
    "# Following the Modified Algorithm of Blame/Praise Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "850365df-dec0-4b8f-a92e-6631d0347707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Step 1: Find all the valid verbs in the sentence and safe them in the format: word, own_index, head_index, tag\n",
    "\n",
    "def is_foreseeability_verb(verb):\n",
    "    # This function checks whether a verb belongs to a predefined set of foreseeability-related verb classes.\n",
    "    foreseeability_classes = {'communication', 'creation', 'consumption', 'competition', 'possession', 'motion'}\n",
    "    synsets = wn.synsets(verb, pos=wn.VERB)  # Fetches all verb synsets for the word\n",
    "    for synset in synsets:\n",
    "        lexname = synset.lexname().split('.')[1]  # Extracts the lexical category (i.e., type of action)\n",
    "        if lexname in foreseeability_classes:  # Checks if the lexical category is in the foreseeability class\n",
    "            return True  # Returns True if the verb matches any foreseeability category\n",
    "    return False  # If no match is found, returns False\n",
    "\n",
    "\n",
    "def is_coercion_verb(verb):\n",
    "    # This function checks whether a verb belongs to a predefined set of coercion-related VerbNet classes.\n",
    "    coercion_classes = {'urge-58.1', 'force-59', 'forbid-67'}\n",
    "    synsets = wn.synsets(verb, pos=wn.VERB)  # Fetches all verb synsets for the word\n",
    "    for synset in synsets:\n",
    "        lemma = synset.lemmas()[0]  # Gets the first lemma for each synset\n",
    "        vn_classes = lemma.key().split('%')[0]  # Extracts the lemma key\n",
    "        vn_class_ids = vn.classids(vn_classes)  # Fetches the VerbNet classes for the lemma\n",
    "        if any(vn_class in coercion_classes for vn_class in vn_class_ids):  # Checks for a match in coercion classes\n",
    "            return True  # If a match is found in coercion classes, return True\n",
    "    return False  # If no match is found, return False\n",
    "\n",
    "\n",
    "def is_valid_verb(verb):\n",
    "    \"\"\"\n",
    "    Check if the given verb passes the foreseeability and coercion checks.\n",
    "    \"\"\"\n",
    "    if is_foreseeability_verb(verb) and not is_coercion_verb(verb):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def find_all_valid_verbs_in_row(row):\n",
    "    \"\"\"\n",
    "    Main function to find valid verbs\n",
    "    \"\"\"\n",
    "    dependencies = row['dependencies']  # Dependency relations for the sentence\n",
    "    tokens_pos = row['tokens_pos']  # POS-tagged tokens for the sentence\n",
    "\n",
    "    all_verbs_list = []\n",
    "\n",
    "    for own_index, (token, pos) in enumerate(tokens_pos):\n",
    "        if 'VERB' in pos:  # Ensure the word is tagged as a verb\n",
    "            if is_valid_verb(token):  # Check if it is valid\n",
    "                # Ensure the dependency has exactly 3 values to unpack\n",
    "                if len(dependencies[own_index]) == 3:\n",
    "                    word, head_index, tag = dependencies[own_index]\n",
    "                    #print(word, own_index + 1, head_index, tag)\n",
    "                    all_verbs_list.append((word, own_index + 1, head_index, tag))\n",
    "    return all_verbs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc1f72ab-8b9a-482b-9f7b-04620ea2aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df['All_Valid_Verbs'] = shuffled_df.apply(find_all_valid_verbs_in_row, axis=1)\n",
    "shuffled_df = shuffled_df[['Sentence', 'Label', 'All_Valid_Verbs'] + [col for col in shuffled_df.columns if col not in ['Sentence', 'Label', 'All_Valid_Verbs']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca0f485-b2fc-449d-8a72-98fe17202932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_agent_validity(agent_combo, position, row):\n",
    "    \n",
    "    agent_is_valid = False\n",
    "    name_addition = None\n",
    "    agent, agent_head, agent_tag = agent_combo\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    entities = row['entities']\n",
    "    entities_str = ' '.join([f\"({tup[0]}, {tup[1]})\" for tup in entities])\n",
    "    dependencies = row['dependencies']\n",
    "    valid_ent_labels = [\"PERSON\", \"NORP\", \"ORG\", \"GPE\"]\n",
    "    valid_additional_words = [\n",
    "        \"accountant\", \"administration\", \"advisor\", \"agent\", \"ambassador\", \"attorney\", \"bureaucrat\", \n",
    "        \"candidate\", \"chancellor\", \"chief\", \"commissioner\", \"congress\", \n",
    "        \"congressman\", \"congresswoman\", \"council\", \"councillor\", \"court\", \"critic\", \"deputy\", \"diplomat\", \n",
    "        \"executive\", \"gentleman\", \"governor\", \"head\", \"house\", \"immigrants\", \"inspector\", \n",
    "        \"journalist\", \"judge\", \"lady\", \"legislator\", \"manager\", \"man\", \"mayor\", \"member\", \"minister\", \"ministry\", \n",
    "        \"monarchy\", \"mr.\", \"mrs.\", \"ms.\", \"officer\", \"office\", \"ombudsman\", \n",
    "        \"parliament\", \"parliamentary\", \"person\", \"police\", \"president\", \"prosecutor\", \"representative\", \n",
    "        \"secretary\", \"secretary\", \"senate\", \"senator\", \"speaker\", \"whip\", \"woman\", \n",
    "        \"he\", \"she\", \"they\", \"i\", \"we\", \"you\",\n",
    "        \"anyone\", \"anybody\", \"everyone\", \"everybody\", \"someone\", \"somebody\", \"no one\", \"nobody\", \"each\", \"both\", \"few\", \"many\", \"several\", \"some\", \n",
    "        \"this\", \"that\", \"these\", \"those\"\n",
    "    ]\n",
    "    \n",
    "    # Check if the related_word is a valid agent based on NER \n",
    "    for entity, label in entities: \n",
    "        if agent in entity and label in valid_ent_labels:  \n",
    "            agent_is_valid = True\n",
    "\n",
    "    # Check if the word is in additional valid agent words\n",
    "    if not agent_is_valid and lemmatizer.lemmatize(agent.lower()) in valid_additional_words:\n",
    "        agent_is_valid = True  \n",
    "\n",
    "    # Check if the word has additional words with \"appos\" or \"flat\" tags connected to it \n",
    "    # (ex. \"Singer, actor and activist Harry Belafonte\" - singer is nsubj (not valid agent) but Harry Belafonte is a valid agent)\n",
    "    for name_combo in dependencies:\n",
    "        if len(agent_combo) == 3:\n",
    "            name, name_head, name_tag = name_combo\n",
    "            if name_head == position and name_tag in [\"flat\", \"appos\"]:\n",
    "                if name in entities_str:\n",
    "                    agent_is_valid = True\n",
    "                    name_addition = name                  \n",
    "    \n",
    "    return agent_is_valid, name_addition\n",
    "\n",
    "def find_valid_agent(verb_combo, row):\n",
    "    \n",
    "    passive = False\n",
    "    agent_is_valid = False\n",
    "    valid_agent = None\n",
    "    name_addition = None\n",
    "    verb, own_index, head_index, tag = verb_combo\n",
    "    #print(\"Verb Combo: \", verb, own_index, head_index, tag)\n",
    "    dependencies = row['dependencies']\n",
    "\n",
    "    for position, agent_combo in enumerate(dependencies):\n",
    "        if len(agent_combo) == 3:\n",
    "            agent, agent_head, agent_tag = agent_combo\n",
    "            #print(\"Agent Combo: \", agent, agent_head, agent_tag)\n",
    "            # Not Passive\n",
    "            if agent_head == own_index and agent_tag in ['nsubj']:\n",
    "                agent_is_valid, name_addition = check_agent_validity(agent_combo, position+1, row)\n",
    "                #print(\"Found own valid agent - not passive: \", agent)\n",
    "            if agent_is_valid == True:\n",
    "                if name_addition != None:\n",
    "                    valid_agent = agent + \" \" + name_addition\n",
    "                else:\n",
    "                    valid_agent = agent\n",
    "                return valid_agent, passive\n",
    "                \n",
    "    for position, agent_combo in enumerate(dependencies):\n",
    "        if len(agent_combo) == 3:\n",
    "            agent, agent_head, agent_tag = agent_combo\n",
    "            #print(\"Agent Combo: \", agent, agent_head, agent_tag)\n",
    "            # Not Passive\n",
    "            if agent_head == head_index and agent_tag in ['nsubj']: \n",
    "                agent_is_valid, name_addition = check_agent_validity(agent_combo, position+1, row)\n",
    "                #print(\"Found head valid agent - not passive: \", agent)\n",
    "            if agent_is_valid == True:\n",
    "                if name_addition != None:\n",
    "                    valid_agent = agent + \" \" + name_addition\n",
    "                else:\n",
    "                    valid_agent = agent\n",
    "                return valid_agent, passive\n",
    "                \n",
    "    for position, agent_combo in enumerate(dependencies):\n",
    "        if len(agent_combo) == 3:\n",
    "            agent, agent_head, agent_tag = agent_combo\n",
    "            #print(\"Agent Combo: \", agent, agent_head, agent_tag)\n",
    "            # Passive\n",
    "            if agent_is_valid == False:\n",
    "                if agent_head == own_index and agent_tag in ['nsubj:pass']:\n",
    "                    passive = True\n",
    "                    agent_is_valid = True\n",
    "                    #print(\"Found own valid agent - passive: \", agent)\n",
    "            if agent_is_valid == True:\n",
    "                valid_agent = agent\n",
    "                return valid_agent, passive\n",
    "                \n",
    "    for position, agent_combo in enumerate(dependencies):\n",
    "        if len(agent_combo) == 3:\n",
    "            agent, agent_head, agent_tag = agent_combo\n",
    "            #print(\"Agent Combo: \", agent, agent_head, agent_tag)\n",
    "            # Checking if the agent of the root of that verb is valid\n",
    "            if agent_head == head_index and agent_tag in ['nsubj:pass']: \n",
    "                passive = True\n",
    "                agent_is_valid = True\n",
    "                #print(\"Found head valid agent - passive: \", agent)\n",
    "            if agent_is_valid == True:\n",
    "                valid_agent = agent\n",
    "                return valid_agent, passive\n",
    "\n",
    "    return valid_agent, passive\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "def find_valid_object(verb_combo, row):\n",
    "    \n",
    "    valid_object = None\n",
    "    xcomp_word = None\n",
    "    dependencies = row['dependencies']\n",
    "    verb, own_index, head_index, tag = verb_combo\n",
    "\n",
    "    # Priority of object tags: obj - xcomp_obj - iobj - xcomp_iobj - obl - xcomp_obl\n",
    "    \n",
    "    for object_combo in dependencies:\n",
    "        if len(object_combo) == 3:\n",
    "            object, object_head, object_tag = object_combo\n",
    "            if object_head == own_index and object_tag == 'obj':\n",
    "                valid_object = object\n",
    "                #print(\"Found own valid obj: \", object)\n",
    "                return valid_object,xcomp_word\n",
    "\n",
    "    for i, xcomp_combo in enumerate(dependencies):\n",
    "        if len(xcomp_combo) == 3:\n",
    "            xcomp, xcomp_head, xcomp_tag = xcomp_combo\n",
    "            if xcomp_head == own_index and xcomp_tag == 'xcomp':\n",
    "                #print(\"Found xcomp: \", xcomp)\n",
    "                for related_to_xcomp in dependencies:\n",
    "                    if len(related_to_xcomp) == 3:\n",
    "                        related_to_xcomp_object, related_to_xcomp_object_head, related_to_xcomp_object_tag = related_to_xcomp\n",
    "                        if related_to_xcomp_object_head == i+1 and related_to_xcomp_object_tag == 'obj':\n",
    "                            valid_object = related_to_xcomp_object\n",
    "                            xcomp_word = xcomp\n",
    "                            #print(\"Found xcomp valid obj: \", object)\n",
    "                            return valid_object,xcomp_word\n",
    "    \n",
    "    for object_combo in dependencies:\n",
    "        if len(object_combo) == 3:\n",
    "            object, object_head, object_tag = object_combo\n",
    "            if object_head == own_index and object_tag == 'iobj':\n",
    "                valid_object = object\n",
    "                #print(\"Found own valid iobj: \", object)\n",
    "                return valid_object,xcomp_word\n",
    "\n",
    "    for i, xcomp_combo in enumerate(dependencies):\n",
    "        if len(xcomp_combo) == 3:\n",
    "            xcomp, xcomp_head, xcomp_tag = xcomp_combo\n",
    "            if xcomp_head == own_index and xcomp_tag == 'xcomp':\n",
    "                #print(\"Found xcomp: \", xcomp)\n",
    "                for related_to_xcomp in dependencies:\n",
    "                    if len(related_to_xcomp) == 3:\n",
    "                        related_to_xcomp_object, related_to_xcomp_object_head, related_to_xcomp_object_tag = related_to_xcomp\n",
    "                        if related_to_xcomp_object_head == i+1 and related_to_xcomp_object_tag == 'iobj':\n",
    "                            xcomp_word = xcomp\n",
    "                            #print(\"Found xcomp valid iobj: \", object)\n",
    "                            return valid_object,xcomp_word\n",
    "    \n",
    "    for object_combo in dependencies:\n",
    "        if len(object_combo) == 3:\n",
    "            object, object_head, object_tag = object_combo\n",
    "            if object_head == own_index and object_tag == 'obl':\n",
    "                valid_object = object\n",
    "                #print(\"Found own valid obl: \", object)\n",
    "                return valid_object,xcomp_word\n",
    "    \n",
    "    for i, xcomp_combo in enumerate(dependencies):\n",
    "        if len(xcomp_combo) == 3:\n",
    "            xcomp, xcomp_head, xcomp_tag = xcomp_combo\n",
    "            if xcomp_head == own_index and xcomp_tag == 'xcomp':\n",
    "                #print(\"Found xcomp: \", xcomp)\n",
    "                for related_to_xcomp in dependencies:\n",
    "                    if len(related_to_xcomp) == 3:\n",
    "                        related_to_xcomp_object, related_to_xcomp_object_head, related_to_xcomp_object_tag = related_to_xcomp\n",
    "                        if related_to_xcomp_object_head == i+1 and related_to_xcomp_object_tag == 'obl':\n",
    "                            valid_object = related_to_xcomp_object\n",
    "                            xcomp_word = xcomp\n",
    "                            #print(\"Found xcomp valid obl: \", object)\n",
    "                            return valid_object,xcomp_word\n",
    "    \n",
    "    return valid_object,xcomp\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "def define_polarity(verb, obj):\n",
    "    \"\"\"\n",
    "    Function to define the polarity of the verb + object combination.\n",
    "    \"\"\"\n",
    "    context = f\"{verb} {obj}\"\n",
    "    verb_sense = lesk(context.split(), verb, 'v')\n",
    "    obj_sense = lesk(context.split(), obj, 'n')\n",
    "    \n",
    "    pos_score = neg_score = 0\n",
    "    \n",
    "    if verb_sense:\n",
    "        swn_verb = swn.senti_synset(verb_sense.name())\n",
    "        pos_score += swn_verb.pos_score()\n",
    "        neg_score += swn_verb.neg_score()\n",
    "    \n",
    "    if obj_sense:\n",
    "        swn_obj = swn.senti_synset(obj_sense.name())\n",
    "        pos_score += swn_obj.pos_score()\n",
    "        neg_score += swn_obj.neg_score()\n",
    "\n",
    "    afinn_score = afinn.score(context)\n",
    "    if afinn_score > 0:\n",
    "        pos_score += afinn_score\n",
    "    else:\n",
    "        neg_score += abs(afinn_score)\n",
    "\n",
    "    subj_pos = sum([1 for token in context.split() if token in opinion_lexicon.positive()])\n",
    "    subj_neg = sum([1 for token in context.split() if token in opinion_lexicon.negative()])\n",
    "    \n",
    "    pos_score += subj_pos\n",
    "    neg_score += subj_neg\n",
    "\n",
    "    return 1 if pos_score > neg_score else 2 if neg_score > pos_score else 0\n",
    "\n",
    "def adjust_sentiment_for_negation(row, polarity, verb_combo):\n",
    "    \"\"\"\n",
    "    Function to adjust the sentiment polarity for negation.\n",
    "    \"\"\"\n",
    "    word, index, head_index, tag = verb_combo\n",
    "    dependencies = row['dependencies']\n",
    "    neg_word = None\n",
    "\n",
    "    for related in dependencies:\n",
    "        if len(related) == 3:\n",
    "            related_word, related_head, related_rel = related\n",
    "            if related_head == index and related_rel in ['advmod'] and related_word in ['not', 'n’t', 'no', 'never', 'barely', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']:\n",
    "                if polarity == 1:\n",
    "                    polarity = 2\n",
    "                    neg_word = related_word\n",
    "                    return polarity, neg_word\n",
    "                if polarity == 2:\n",
    "                    polarity = 1\n",
    "                    neg_word = related_word\n",
    "                    return polarity, neg_word\n",
    "    return polarity, neg_word\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "def find_all_valid_events_and_polarities(row, all_verbs_list):\n",
    "\n",
    "    all_valid_events_and_polarities = []\n",
    "    valid_agent = None\n",
    "    valid_object = None\n",
    "    valid_xcomp = None\n",
    "    neg_word = None\n",
    "    polarity = 0\n",
    "\n",
    "    for verb_combo in all_verbs_list:\n",
    "        verb, own_index, head_index, tag = verb_combo\n",
    "\n",
    "        # Find Valid Agent for that verb\n",
    "        valid_agent, passive = find_valid_agent(verb_combo, row)\n",
    "        if valid_agent == None:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Find Object for that verb\n",
    "        # 2 different algorithms for passive and not passive\n",
    "        if passive == False:\n",
    "            # Looking for own object or over xcomp\n",
    "            valid_object, valid_xcomp = find_valid_object(verb_combo, row)\n",
    "            if valid_object == None:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            # Passive means that nsubj:pass is an object and agent is obl:agent (obl?)\n",
    "            for object_combo in row['dependencies']:\n",
    "                if len(object_combo) == 3:\n",
    "                    object, object_head, object_tag = object_combo\n",
    "                    if object_head == own_index and object_tag == 'obl:agent':\n",
    "                        valid_object = valid_agent\n",
    "                        valid_agent = None\n",
    "                        # Check if that obl is a valid agent\n",
    "                        if check_agent_validity(object, row)[0] == True:\n",
    "                            valid_agent = object\n",
    "                        if valid_agent == None:\n",
    "                            continue\n",
    "            if valid_object == None:\n",
    "                continue\n",
    "\n",
    "        \n",
    "        # Define polarity of the combination verb + object\n",
    "        if valid_object != None:\n",
    "            polarity = define_polarity(verb, valid_object)\n",
    "\n",
    "        \n",
    "        # Adjust polarity according to the negations\n",
    "        if polarity != 0:\n",
    "            polarity, neg_word = adjust_sentiment_for_negation(row, polarity, verb_combo)\n",
    "\n",
    "        # If polarity was chenged - add negative word to the verb for better clarity\n",
    "        if neg_word != None:\n",
    "            verb = neg_word + \" \" + verb\n",
    "        \n",
    "        # If there was xcomp - add it between verb and object\n",
    "        if valid_xcomp != None:\n",
    "            #print(\"Added xcomp to object\")\n",
    "            valid_object = valid_xcomp + \" \" + valid_object\n",
    "    \n",
    "        # Append triple (valid_agent, verb, valid_object) and polarity to the list\n",
    "        if valid_agent != None and valid_object != None:\n",
    "            #print(\"Valid Agent: \", valid_agent)\n",
    "            #print(\"Verb: \", verb, \" - position: \", own_index)\n",
    "            #print(\"Valid Object: \", valid_object)\n",
    "            #print(\"Final polarity: \", polarity)\n",
    "            all_valid_events_and_polarities.append((valid_agent, verb, valid_object, polarity))\n",
    "    \n",
    "    return all_valid_events_and_polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d961942e-46e1-4e00-b066-b0e1134d94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_algorithm(row):\n",
    "    all_verbs_list = find_all_valid_verbs_in_row(row) # Step 1 - Find all the valid verbs in the sentence and safe them in the format: word, own_index, head_index, tag\n",
    "    if len(all_verbs_list) == 0:\n",
    "        return 0\n",
    "\n",
    "    triplets_and_polarities = find_all_valid_events_and_polarities(row, all_verbs_list) # Step 2 - For each valid verb find its valid agent, object, define polarity and safe them in the format: agent, verb, object, polarity\n",
    "    if len(triplets_and_polarities) == 0:\n",
    "        return 0\n",
    "    return triplets_and_polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02580918-d1f9-4eb6-a856-50ed0254b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df['All_Triplets_and_Polarities'] = shuffled_df.apply(new_algorithm, axis=1)\n",
    "shuffled_df = shuffled_df[['Sentence', 'Label', 'All_Triplets_and_Polarities'] + [col for col in shuffled_df.columns if col not in ['Sentence', 'Label', 'All_Triplets_and_Polarities']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fb5a3ae-a5a3-4d02-9a83-ab3cfd2157f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>All_Triplets_and_Polarities</th>\n",
       "      <th>All_Valid_Verbs</th>\n",
       "      <th>Their_Label</th>\n",
       "      <th>tokens_pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2011, of State Hillary Clinton promised the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(promised, 8, 0, root), (use, 18, 8, xcomp)]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(In, ADP), (2011, NUM), (,, PUNCT), (of, ADP)...</td>\n",
       "      <td>[(2011, DATE), (State, ORG), (Hillary Clinton,...</td>\n",
       "      <td>[(In, 2, case), (2011, 8, obl), (,, 2, punct),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>’ Today saw the debut of ”,” a new social expe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(saw, 3, 0, root), (playing, 15, 13, acl)]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(’, PUNCT), (Today, NOUN), (saw, VERB), (the,...</td>\n",
       "      <td>[(Twitch, PRODUCT)]</td>\n",
       "      <td>[(’, 3, punct), (Today, 3, nsubj), (saw, 0, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer, actor and activist Harry Belafonte, 88...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Singer Harry, announce, endorsement, 1)]</td>\n",
       "      <td>[(announce, 12, 0, root), (avowed, 20, 21, amod)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Singer, NOUN), (,, PUNCT), (actor, NOUN), (a...</td>\n",
       "      <td>[(Harry Belafonte, PERSON), (88, DATE), (Democ...</td>\n",
       "      <td>[(Singer, 12, nsubj), (,, 3, punct), (actor, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week, Roberts said the teams medical staf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(said, 5, 0, root), (surprised, 12, 5, ccomp)...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Last, ADJ), (week, NOUN), (,, PUNCT), (Rober...</td>\n",
       "      <td>[(Last week, DATE), (Roberts, PERSON), (Kersha...</td>\n",
       "      <td>[(Last, 2, amod), (week, 5, obl:tmod), (,, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indeed, I believe that Waitrose does more than...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Waitrose, does, more, 2), (Waitrose, support...</td>\n",
       "      <td>[(does, 7, 4, ccomp), (support, 14, 7, advcl)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Indeed, ADV), (,, PUNCT), (I, PRON), (believ...</td>\n",
       "      <td>[(Waitrose, ORG), (UK, GPE)]</td>\n",
       "      <td>[(Indeed, 4, advmod), (,, 4, punct), (I, 4, ns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bombelyn, who had worked with a grassroots gro...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Bombelyn, attacked, Cahill, 2), (Bombelyn, c...</td>\n",
       "      <td>[(worked, 5, 1, acl:relcl), (attacked, 23, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(Bombelyn, PROPN), (,, PUNCT), (who, PRON), (...</td>\n",
       "      <td>[(Bombelyn, PERSON), (Rutgers University, ORG)...</td>\n",
       "      <td>[(Bombelyn, 23, nsubj), (,, 1, punct), (who, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>After the first known use of a military-grade ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Britain, blamed, President, 2), (Britain, ex...</td>\n",
       "      <td>[(blamed, 22, 0, root), (attempted, 29, 30, am...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(After, ADP), (the, DET), (first, ADJ), (know...</td>\n",
       "      <td>[(first, ORDINAL), (European, NORP), (World Wa...</td>\n",
       "      <td>[(After, 5, case), (the, 5, det), (first, 5, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Of the 712 Democratic superdelegates, 449 (or ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(449 percent, support, Clinton, 1)]</td>\n",
       "      <td>[(support, 15, 0, root), (according, 18, 24, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Of, ADP), (the, DET), (712, NUM), (Democrati...</td>\n",
       "      <td>[(712, CARDINAL), (Democratic, NORP), (449, CA...</td>\n",
       "      <td>[(Of, 5, case), (the, 5, det), (712, 5, nummod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>From the start of the war, the Pentagon has ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Pentagon, hoped, start, 0), (Pentagon, surre...</td>\n",
       "      <td>[(hoped, 11, 0, root), (invading, 17, 18, amod...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(From, ADP), (the, DET), (start, NOUN), (of, ...</td>\n",
       "      <td>[(Pentagon, ORG), (Iraqi, NORP)]</td>\n",
       "      <td>[(From, 3, case), (the, 3, det), (start, 11, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The dream scenario for the Giants is Aaron Rod...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(frozen, 14, 8, acl), (watching, 20, 8, advcl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(The, DET), (dream, NOUN), (scenario, NOUN), ...</td>\n",
       "      <td>[(Giants, ORG), (Aaron Rodgers, PERSON)]</td>\n",
       "      <td>[(The, 3, det), (dream, 3, compound), (scenari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  Label  \\\n",
       "0   In 2011, of State Hillary Clinton promised the...      0   \n",
       "1   ’ Today saw the debut of ”,” a new social expe...      0   \n",
       "2   Singer, actor and activist Harry Belafonte, 88...      1   \n",
       "3   Last week, Roberts said the teams medical staf...      0   \n",
       "4   Indeed, I believe that Waitrose does more than...      0   \n",
       "..                                                ...    ...   \n",
       "95  Bombelyn, who had worked with a grassroots gro...      1   \n",
       "96  After the first known use of a military-grade ...      1   \n",
       "97  Of the 712 Democratic superdelegates, 449 (or ...      1   \n",
       "98  From the start of the war, the Pentagon has ho...      0   \n",
       "99  The dream scenario for the Giants is Aaron Rod...      0   \n",
       "\n",
       "                          All_Triplets_and_Polarities  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2          [(Singer Harry, announce, endorsement, 1)]   \n",
       "3                                                   0   \n",
       "4   [(Waitrose, does, more, 2), (Waitrose, support...   \n",
       "..                                                ...   \n",
       "95  [(Bombelyn, attacked, Cahill, 2), (Bombelyn, c...   \n",
       "96  [(Britain, blamed, President, 2), (Britain, ex...   \n",
       "97               [(449 percent, support, Clinton, 1)]   \n",
       "98  [(Pentagon, hoped, start, 0), (Pentagon, surre...   \n",
       "99                                                  0   \n",
       "\n",
       "                                      All_Valid_Verbs  Their_Label  \\\n",
       "0       [(promised, 8, 0, root), (use, 18, 8, xcomp)]            0   \n",
       "1         [(saw, 3, 0, root), (playing, 15, 13, acl)]            0   \n",
       "2   [(announce, 12, 0, root), (avowed, 20, 21, amod)]            1   \n",
       "3   [(said, 5, 0, root), (surprised, 12, 5, ccomp)...            1   \n",
       "4      [(does, 7, 4, ccomp), (support, 14, 7, advcl)]            1   \n",
       "..                                                ...          ...   \n",
       "95  [(worked, 5, 1, acl:relcl), (attacked, 23, 0, ...            2   \n",
       "96  [(blamed, 22, 0, root), (attempted, 29, 30, am...            0   \n",
       "97  [(support, 15, 0, root), (according, 18, 24, c...            0   \n",
       "98  [(hoped, 11, 0, root), (invading, 17, 18, amod...            0   \n",
       "99  [(frozen, 14, 8, acl), (watching, 20, 8, advcl...            0   \n",
       "\n",
       "                                           tokens_pos  \\\n",
       "0   [(In, ADP), (2011, NUM), (,, PUNCT), (of, ADP)...   \n",
       "1   [(’, PUNCT), (Today, NOUN), (saw, VERB), (the,...   \n",
       "2   [(Singer, NOUN), (,, PUNCT), (actor, NOUN), (a...   \n",
       "3   [(Last, ADJ), (week, NOUN), (,, PUNCT), (Rober...   \n",
       "4   [(Indeed, ADV), (,, PUNCT), (I, PRON), (believ...   \n",
       "..                                                ...   \n",
       "95  [(Bombelyn, PROPN), (,, PUNCT), (who, PRON), (...   \n",
       "96  [(After, ADP), (the, DET), (first, ADJ), (know...   \n",
       "97  [(Of, ADP), (the, DET), (712, NUM), (Democrati...   \n",
       "98  [(From, ADP), (the, DET), (start, NOUN), (of, ...   \n",
       "99  [(The, DET), (dream, NOUN), (scenario, NOUN), ...   \n",
       "\n",
       "                                             entities  \\\n",
       "0   [(2011, DATE), (State, ORG), (Hillary Clinton,...   \n",
       "1                                 [(Twitch, PRODUCT)]   \n",
       "2   [(Harry Belafonte, PERSON), (88, DATE), (Democ...   \n",
       "3   [(Last week, DATE), (Roberts, PERSON), (Kersha...   \n",
       "4                        [(Waitrose, ORG), (UK, GPE)]   \n",
       "..                                                ...   \n",
       "95  [(Bombelyn, PERSON), (Rutgers University, ORG)...   \n",
       "96  [(first, ORDINAL), (European, NORP), (World Wa...   \n",
       "97  [(712, CARDINAL), (Democratic, NORP), (449, CA...   \n",
       "98                   [(Pentagon, ORG), (Iraqi, NORP)]   \n",
       "99           [(Giants, ORG), (Aaron Rodgers, PERSON)]   \n",
       "\n",
       "                                         dependencies  \n",
       "0   [(In, 2, case), (2011, 8, obl), (,, 2, punct),...  \n",
       "1   [(’, 3, punct), (Today, 3, nsubj), (saw, 0, ro...  \n",
       "2   [(Singer, 12, nsubj), (,, 3, punct), (actor, 1...  \n",
       "3   [(Last, 2, amod), (week, 5, obl:tmod), (,, 5, ...  \n",
       "4   [(Indeed, 4, advmod), (,, 4, punct), (I, 4, ns...  \n",
       "..                                                ...  \n",
       "95  [(Bombelyn, 23, nsubj), (,, 1, punct), (who, 5...  \n",
       "96  [(After, 5, case), (the, 5, det), (first, 5, a...  \n",
       "97  [(Of, 5, case), (the, 5, det), (712, 5, nummod...  \n",
       "98  [(From, 3, case), (the, 3, det), (start, 11, o...  \n",
       "99  [(The, 3, det), (dream, 3, compound), (scenari...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc75981-6ec5-4b5b-934f-10d8d1a870ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['All_Triplets_and_Polarities'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c83bd44-2929-4853-8cf8-2b7021c5ea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['All_Valid_Verbs'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77ccf406-0ffc-4fc3-8ff5-085ac6b704a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "All_Triplets_and_Polarities\n",
       "0                                                                       38\n",
       "[(Lebanon, accuses, Israel, 2)]                                          1\n",
       "[(Sen. Booker, testified, move, 0), (we, count, him, 0)]                 1\n",
       "[(Tyler Florence, tackles, challenge, 2)]                                1\n",
       "[(De Blasio, castigated, Trump, 2), (De Blasio, sharing, values, 0)]     1\n",
       "                                                                        ..\n",
       "[(Snowden, performed, service, 0)]                                       1\n",
       "[(Obama, failed, LGBTs, 2)]                                              1\n",
       "[(Jim Harbaugh, asked, autograph it, 0)]                                 1\n",
       "[(Trump, criticized, time, 2)]                                           1\n",
       "[(Pentagon, hoped, start, 0), (Pentagon, surrender, help, 1)]            1\n",
       "Name: count, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['All_Triplets_and_Polarities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbfcce-b466-47a0-8828-6cffda8713e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8776b-d387-4f43-a052-aa6ad7d510a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd7014b6-a2bb-4367-9fd1-7cb0825e5f0a",
   "metadata": {},
   "source": [
    "# Export in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f01c3852-ef74-496c-aeb5-95f01c929ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the first x rows to an Excel file\n",
    "shuffled_df.to_excel('shuffled_1_df_4th_model_more_agents_100_rows.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e411d9-9a41-4d60-a54b-f9f59841d57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfcbf388-5cb9-488a-b5c0-0370e0b6d003",
   "metadata": {},
   "source": [
    "# ГЛАГОЛЫ ТОЖЕ МОЖНО ПРОВЕРИТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b65566c8-3a3c-4077-821f-3fcc506b88ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Waitrose', 'does', 'more', 2)\n",
      "('Trump', 'doing', 'job', 2)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for events_list in shuffled_df['All_Triplets_and_Polarities']:\n",
    "    if events_list != 0:\n",
    "        for event in events_list:\n",
    "            if event[1] in ['do', 'does', 'did', 'done', 'doing']:\n",
    "                counter = counter + 1\n",
    "                print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99772cb6-7725-4552-a3e7-1730dac6bf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3e25528-6c7c-4c8f-bffe-b0b061c37c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter / shuffled_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "828b8147-936a-466b-8c3d-22810ed6440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for events_list in shuffled_df['All_Triplets_and_Polarities']:\n",
    "    if events_list != 0:\n",
    "        for event in events_list:\n",
    "            if event[1] in [\"be\", \"am\", \"is\", \"are\", \"was\", \"were\", \"being\", \"been\"]:\n",
    "                counter = counter + 1\n",
    "                print(event)\n",
    "                print(events_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea7a846d-4cca-41d8-815a-d04d4a4ac947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "067fd5c4-aee3-4fff-a4c7-cf1cce4b39dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter / shuffled_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880d373-a74d-48a4-a0f7-1499f9cfd9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c154df-e4b7-4e72-9042-fda3d0938737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6aa51dcb-9bd7-4adc-af2d-90655ed7b59d",
    "5b4b9a5d-f5f1-4b41-89b1-ef0f7ec9269b",
    "XgpcdWkBTA2i"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0489b43fc7e64734882843d7d1dbccce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04d91f88d2bd41c2911b27882b1bc3c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fb17667761c4591ab2da8e3f71fa0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c9aa0c7fa734470bfc3feed6592d3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6835ae446b484d3ca602ec2f617aaff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0dc4784cf42446fb83ce5e6f1162d21",
      "placeholder": "​",
      "style": "IPY_MODEL_04d91f88d2bd41c2911b27882b1bc3c4",
      "value": " 386k/? [00:00&lt;00:00, 11.6MB/s]"
     }
    },
    "9ddd39e4df4f422d894bd00d63808d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c9aa0c7fa734470bfc3feed6592d3bc",
      "placeholder": "​",
      "style": "IPY_MODEL_d29596beefdc42bea19fafd84f93dadb",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "
     }
    },
    "a0dc4784cf42446fb83ce5e6f1162d21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae273c49ff2a4099804ec2402c4e2d9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aee8df7ec2544bd89bdfbdb36a75191f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ddd39e4df4f422d894bd00d63808d90",
       "IPY_MODEL_b74d16cecf6e4c81b3ffd3df6be7845b",
       "IPY_MODEL_6835ae446b484d3ca602ec2f617aaff4"
      ],
      "layout": "IPY_MODEL_ae273c49ff2a4099804ec2402c4e2d9a"
     }
    },
    "b74d16cecf6e4c81b3ffd3df6be7845b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0489b43fc7e64734882843d7d1dbccce",
      "max": 47900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fb17667761c4591ab2da8e3f71fa0bd",
      "value": 47900
     }
    },
    "d29596beefdc42bea19fafd84f93dadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
